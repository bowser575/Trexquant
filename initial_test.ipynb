{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "import re\n",
    "\n",
    "def extract_numeric_value(text):\n",
    "    \"\"\"\n",
    "    Extract and normalize a numeric value, handling negative numbers in various formats.\n",
    "    \n",
    "    Args:\n",
    "        text: Text containing a potential numeric value\n",
    "        \n",
    "    Returns:\n",
    "        Normalized numeric value as a string, or None if no valid number found\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "        \n",
    "    # Clean the text\n",
    "    cleaned_text = text.replace('$', '').replace(',', '').strip()\n",
    "    \n",
    "    # Handle case where opening parenthesis is present but closing one is missing\n",
    "    # This happens when parentheses are split across cells\n",
    "    if cleaned_text.startswith('(') and not cleaned_text.endswith(')'):\n",
    "        match = re.search(r'\\(?([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle normal parentheses case\n",
    "    if '(' in cleaned_text and ')' in cleaned_text:\n",
    "        # Extract the number inside parentheses\n",
    "        match = re.search(r'\\(([\\d\\.]+)\\)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle numbers with explicit negative signs\n",
    "    if re.search(r'^\\s*[\\-−–]', cleaned_text):  # Handle various dash characters\n",
    "        match = re.search(r'([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Special case for closing parenthesis only - ignore it\n",
    "    if cleaned_text == ')':\n",
    "        return None\n",
    "    \n",
    "    # Normal number extraction\n",
    "    match = re.search(r'([\\d\\.]+)', cleaned_text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def check_eps_pattern(text):\n",
    "    \"\"\"\n",
    "    Check if text contains patterns indicating EPS (Earnings Per Share) information.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to check for EPS patterns\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating if an EPS pattern was found\n",
    "    \"\"\"\n",
    "    text = text.lower().strip()\n",
    "    patterns = [\n",
    "        r'(?:basic|diluted)?\\s*earnings\\s*(?:\\(loss\\))?\\s*per\\s*(?:common|outstanding|ordinary)?\\s*share',\n",
    "        r'(?:basic|diluted)?\\s*loss\\s*per\\s*(?:common|outstanding|ordinary)?\\s*share',\n",
    "        r'earnings\\s*\\(loss\\)\\s*per\\s*(?:common|outstanding|ordinary)?\\s*share',\n",
    "        r'net\\s*(?:income|loss|earnings)\\s*(?:attributable\\s*to\\s*[a-z\\s]+)?\\s*per\\s*share',\n",
    "        r'income\\s*\\(loss\\)\\s*per\\s*share',\n",
    "        r'\\beps\\b',\n",
    "        r'earnings\\s*per\\s*share',\n",
    "        r'net\\s+income\\s+available\\s+to\\s+common\\s+stockholders\\s+per\\s+share',\n",
    "        r'net\\s+income\\s+per\\s+common\\s+share',\n",
    "        r'net\\s*(?:\\(loss\\)\\s*income|income\\s*\\(loss\\))\\s*per\\s*share'\n",
    "\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            # Exclude weighted average share patterns\n",
    "            if re.search(r'weighted|average|shares\\s*outstanding', text, re.IGNORECASE):\n",
    "                continue\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def is_basic_eps(text):\n",
    "    \"\"\"\n",
    "    Check if text refers to basic EPS, diluted EPS, or both.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to check for basic/diluted indicators\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (is_basic, is_diluted) booleans\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        has_basic = bool(re.search(r'\\bbasic\\b', text))\n",
    "        has_diluted = bool(re.search(r'\\bdiluted\\b', text))\n",
    "                # Special case: \"basic and diluted\" or \"basic & diluted\" should count as both\n",
    "        if re.search(r'basic\\s+(?:and|&)\\s+diluted', text) or re.search(r'diluted\\s+(?:and|&)\\s+basic', text):\n",
    "            has_basic = True\n",
    "            has_diluted = True\n",
    "            print('HERE IN basic')\n",
    "        return has_basic, has_diluted\n",
    "    except Exception as e:\n",
    "        print(f\"Error in is_basic_eps: {e}\")\n",
    "        return False, False\n",
    "\n",
    "def is_gaap_eps(text):\n",
    "    \"\"\"\n",
    "    Check if text refers to GAAP (not non-GAAP/adjusted) EPS.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to check for GAAP/non-GAAP indicators\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating if EPS is GAAP (True) or non-GAAP (False)\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    return not re.search(r'non-gaap|non\\s*gaap|adjusted', text)\n",
    "\n",
    "def select_eps_value(row_values, row_text, table_idx):\n",
    "    \"\"\"\n",
    "    Select the appropriate EPS value based on priority rules and create the final EPS entry.\n",
    "    \n",
    "    Args:\n",
    "        row_values: List of dictionaries containing EPS values and classifications\n",
    "        row_text: Text from the row where EPS pattern was found\n",
    "        table_idx: Table index for reference\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with selected EPS information\n",
    "    \"\"\"\n",
    "    if not row_values:\n",
    "        return None\n",
    "        \n",
    "    # Default to the first value entry\n",
    "    selected_entry = row_values[0]\n",
    "    \n",
    "    # First try to find basic EPS (highest priority)\n",
    "    basic_values = [item for item in row_values if item['basic']]\n",
    "    if basic_values:\n",
    "        selected_entry = basic_values[0]\n",
    "    else:\n",
    "        # If no basic found, try diluted\n",
    "        diluted_values = [item for item in row_values if item['diluted']]\n",
    "        if diluted_values:\n",
    "            selected_entry = diluted_values[0]\n",
    "    \n",
    "    # Extract just the values for cleaner output\n",
    "    value_list = [item['value'] for item in row_values]\n",
    "    \n",
    "    # Create the final EPS entry\n",
    "    return {\n",
    "        'table_idx': table_idx,\n",
    "        'row_text': row_text[:100],  # Truncate for readability\n",
    "        'basic': selected_entry['basic'],\n",
    "        'diluted': selected_entry['diluted'],\n",
    "        'gaap': selected_entry['gaap'],\n",
    "        'value': selected_entry['value'],  # Prioritized value\n",
    "        'all_values': value_list\n",
    "    }\n",
    "\n",
    "def extract_eps_from_filing(file_path, verbose=False):\n",
    "    \"\"\"\n",
    "    Extract EPS values from an HTML financial filing.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the HTML filing\n",
    "        verbose: Whether to print detailed information during extraction\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing extracted EPS information\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # Initialize the results list\n",
    "    eps_values = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        html = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    for table_idx, table in enumerate(tables):\n",
    "        # Get all rows for sequential access\n",
    "        rows = table.find_all('tr')\n",
    "        \n",
    "        for i, row in enumerate(rows):\n",
    "            row_text = row.get_text().lower().strip().replace(':', '')\n",
    "            \n",
    "            if check_eps_pattern(row_text):\n",
    "                # Look for cells containing a value in current row\n",
    "                cells = row.find_all('td')\n",
    "                if verbose:\n",
    "                    print(f\"Found EPS pattern in row: {row_text[:100]}...\")\n",
    "                \n",
    "                # Get basic/diluted classification\n",
    "                basic, diluted = is_basic_eps(row_text)\n",
    "                \n",
    "                # Get GAAP classification\n",
    "                gaap = is_gaap_eps(row_text)\n",
    "                \n",
    "                # Check if this row has values\n",
    "                found_value = False\n",
    "                row_values = []\n",
    "                \n",
    "                for cell in cells:\n",
    "                    cell_text = cell.get_text().strip()\n",
    "                    \n",
    "                    value = extract_numeric_value(cell_text)\n",
    "    \n",
    "                    if value is not None:\n",
    "                        found_value = True\n",
    "                        \n",
    "                        row_values.append({\n",
    "                            'value': value,\n",
    "                            'basic': basic,\n",
    "                            'diluted': diluted,\n",
    "                            'gaap': gaap\n",
    "                        })\n",
    "                        \n",
    "                        if verbose:\n",
    "                            print(f\"Found value in current row: {value}\")\n",
    "                \n",
    "                # If no values found in current row or we suspect partial parentheses, check the next row\n",
    "                while (not found_value and i + 1 < len(rows)):\n",
    "                    next_row = rows[i + 1]\n",
    "                    next_cells = next_row.find_all('td')\n",
    "                    next_row_text = next_row.get_text().lower().strip().replace(':', '')\n",
    "                    \n",
    "                    # Get classifications from next row\n",
    "                    if not(basic and diluted):\n",
    "                        basic, diluted = is_basic_eps(next_row_text)\n",
    "                    gaap = is_gaap_eps(next_row_text)\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"Checking next row for values...\")\n",
    "                        print(next_row_text)\n",
    "                    for cell in next_cells:\n",
    "                        cell_text = cell.get_text().strip()\n",
    "                        value = extract_numeric_value(cell_text)\n",
    "                        \n",
    "                        if value is not None:\n",
    "                            found_value = True\n",
    "                            row_values.append({\n",
    "                                'value': value,\n",
    "                                'basic': basic,\n",
    "                                'diluted': diluted,\n",
    "                                'gaap': gaap\n",
    "                            })\n",
    "                            \n",
    "                            if verbose:\n",
    "                                print(f\"Found value in next row: {value}\")\n",
    "                    i+=1\n",
    "                # If we found at least one value, use helper method to select and create entry\n",
    "                if row_values:\n",
    "                    eps_entry = select_eps_value(row_values, row_text, table_idx)\n",
    "                    eps_values.append(eps_entry)\n",
    "    \n",
    "    return eps_values\n",
    "\n",
    "\n",
    "def select_final_eps(eps_values):\n",
    "    \"\"\"\n",
    "    Select the final EPS value from all extracted values based on row text patterns and priority rules.\n",
    "    \n",
    "    Args:\n",
    "        eps_values: List of dictionaries containing extracted EPS information\n",
    "        \n",
    "    Returns:\n",
    "        Single EPS value or None if no valid value found\n",
    "    \"\"\"\n",
    "    if not eps_values:\n",
    "        return None\n",
    "    \n",
    "    # If there's only one value, return it directly\n",
    "    if len(eps_values) == 1:\n",
    "        return eps_values[0]['value']\n",
    "    \n",
    "    # Define pattern priority list (highest priority first)\n",
    "    # Each entry is (regex pattern, score adjustment)\n",
    "    pattern_priorities = [\n",
    "        # Basic net income/earnings per share (highest priority)\n",
    "        (r'basic\\s+(?:and|&)\\s+diluted\\s+(?:loss|earnings|income)\\s+per\\s+share', 1200),\n",
    "        (r'(?:loss|earnings|income)\\s+per\\s+share\\s+[-–]\\s+basic\\s+(?:and|&)\\s+diluted', 1200),\n",
    "        (r'basic.*net\\s+(?:income|earnings).*per\\s+share', 1000),\n",
    "        \n",
    "        # Basic EPS patterns (very high priority)\n",
    "        (r'basic\\s+earnings\\s+per\\s+(?:common\\s+)?share', 900),\n",
    "        (r'earnings\\s+per\\s+(?:common\\s+)?share.*basic', 900),\n",
    "        (r'net\\s+income.*per\\s+(?:common\\s+)?share.*basic', 900),\n",
    "        \n",
    "        # Important: Add patterns for \"earnings (loss)\" format (high priority)\n",
    "        (r'earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share', 850),\n",
    "        (r'net\\s+earnings\\s*\\(loss\\)\\s*per\\s+share', 850),\n",
    "        (r'\\(loss\\)\\s*earnings\\s*per\\s+(?:common\\s+)?share', 850),\n",
    "        \n",
    "        # Income/earnings per share (likely basic if not specified)\n",
    "        (r'net\\s+(?:income|earnings).*per\\s+share', 800),\n",
    "        (r'net\\s+income\\s+per\\s+common\\s+share', 800),  # High priority\n",
    "        (r'income.*per\\s+share', 700),\n",
    "        (r'earnings\\s+per\\s+(?:common\\s+)?share', 700),\n",
    "        \n",
    "        # Loss per share (still high priority)\n",
    "        (r'basic.*loss\\s+per\\s+share', 650),\n",
    "        (r'net\\s+loss.*per\\s+share', 650),\n",
    "        (r'loss\\s+per\\s+share', 650),\n",
    "        \n",
    "        # GAAP EPS terms\n",
    "        (r'gaap.*earnings\\s+per\\s+share', 600),\n",
    "        \n",
    "        # Specific types of basic EPS\n",
    "        (r'basic\\s+.*per\\s+share', 550),\n",
    "        \n",
    "        # Diluted net income/earnings per share (medium priority)\n",
    "        (r'diluted.*net\\s+(?:income|earnings).*per\\s+share', 500),\n",
    "        \n",
    "        # Diluted EPS patterns\n",
    "        (r'diluted\\s+earnings\\s+per\\s+(?:common\\s+)?share', 400),\n",
    "        (r'earnings\\s+per\\s+(?:common\\s+)?share.*diluted', 400),\n",
    "        \n",
    "        # Generic diluted patterns\n",
    "        (r'diluted\\s+.*per\\s+share', 300),\n",
    "        \n",
    "        # Non-GAAP or adjusted terms (lower priority)\n",
    "        (r'adjusted\\s+(?:basic\\s+)?earnings\\s+per\\s+share', 200),\n",
    "        (r'non-gaap.*earnings\\s+per\\s+share', 100),\n",
    "        (r'adjusted', 50),\n",
    "        \n",
    "        # Generic EPS terms (lowest priority, but still valid)\n",
    "        (r'per\\s+share', 25),\n",
    "        (r'eps', 20),\n",
    "    ]\n",
    "    \n",
    "    scored_values = []\n",
    "    for idx, entry in enumerate(eps_values):\n",
    "        # Start with a base score\n",
    "        score = 0\n",
    "        row_text = entry['row_text'].lower().replace(':', '')\n",
    "        \n",
    "        # Debug - print the exact row text being matched\n",
    "        print(f\"Matching text: '{row_text}'\")\n",
    "        \n",
    "        # Add score based on pattern matches\n",
    "        matched_pattern = None\n",
    "        for pattern, pattern_score in pattern_priorities:\n",
    "            if re.search(pattern, row_text):\n",
    "                score += pattern_score\n",
    "                matched_pattern = pattern\n",
    "                break  # Only apply the highest matching pattern\n",
    "        \n",
    "        # Add additional score components\n",
    "        # 1. Prioritize basic over diluted\n",
    "        if entry['basic']:\n",
    "            score += 100\n",
    "        elif entry['diluted']:\n",
    "            score += 10\n",
    "            \n",
    "        # 2. Prioritize GAAP over non-GAAP\n",
    "        if entry['gaap']:\n",
    "            score += 20\n",
    "        \n",
    "        # 3. Check numerical reasonableness (EPS values are typically between -100 and 100)\n",
    "        try:\n",
    "            value_float = float(entry['value'])\n",
    "            if -20 <= value_float <= 20:\n",
    "                # Most reasonable EPS range\n",
    "                score += 100  # Increased from 15 to 100\n",
    "            elif -100 <= value_float <= 100:\n",
    "                # Wider but still reasonable EPS range\n",
    "                score += 50\n",
    "            elif -1000 <= value_float <= 1000:\n",
    "                # Unusual but possible range\n",
    "                score -= 100  # Increased penalty\n",
    "            else:\n",
    "                # Very likely not an EPS value (e.g., shares outstanding, total earnings in millions)\n",
    "                score -= 500  # Much stronger penalty\n",
    "        except ValueError:\n",
    "            score -= 50  \n",
    "            \n",
    "        scored_values.append({\n",
    "            'index': idx,\n",
    "            'score': score,\n",
    "            'value': entry['value'],\n",
    "            'original': entry,\n",
    "            'row_text': row_text,\n",
    "            'matched_pattern': matched_pattern\n",
    "        })\n",
    "    \n",
    "    # Sort by score in descending order\n",
    "    scored_values.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # For debugging\n",
    "    for i, sv in enumerate(scored_values[:3]):  # Show top 3\n",
    "        print(f\"Candidate {i+1}: Score {sv['score']}, Value: {sv['value']}\")\n",
    "        print(f\"  Row text: {sv['row_text'][:80]}...\")\n",
    "        print(f\"  Matched pattern: {sv['matched_pattern']}\")\n",
    "    \n",
    "    # Return the highest scoring value\n",
    "    if scored_values:\n",
    "        top_score = scored_values[0]['score']\n",
    "        top_row_text = scored_values[0]['row_text']\n",
    "        top_row_value = scored_values[0]['value']\n",
    "        \n",
    "        # Find all entries with the same row text and score\n",
    "        identical_rows = [\n",
    "            sv for sv in scored_values \n",
    "            if (sv['score'] == top_score and sv['row_text'] == top_row_text) and sv['value'] !=top_row_value\n",
    "        ]\n",
    "        \n",
    "        if len(identical_rows) > 0:\n",
    "            print(f\"Found {len(identical_rows)} rows with identical text and score: '{top_row_text[:50]}...'\")\n",
    "            \n",
    "            # Sum the values\n",
    "            total_value = float(top_row_value)\n",
    "            for row in identical_rows:\n",
    "                try:\n",
    "                    total_value += float(row['value'])\n",
    "                except ValueError:\n",
    "                    # Skip non-numeric values\n",
    "                    print(f\"Warning: Could not convert '{row['value']}' to float for summation\")\n",
    "            \n",
    "            # Return the sum as a string with the same precision as the original values\n",
    "            # (Get decimal places from the first value as a reference)\n",
    "            try:\n",
    "                decimal_places = len(identical_rows[0]['value'].split('.')[-1]) if '.' in identical_rows[0]['value'] else 0\n",
    "                return f\"{total_value:.{decimal_places}f}\"\n",
    "            except:\n",
    "                # Fallback to basic formatting if precision detection fails\n",
    "                return str(total_value)\n",
    "        \n",
    "        # If no identical rows, return the highest scoring value\n",
    "        return scored_values[0]['value']\n",
    "\n",
    "    \n",
    "    return None\n",
    "def process_directory(directory_path, verbose=False):\n",
    "    \"\"\"\n",
    "    Process all HTML files in a directory to extract EPS values.\n",
    "    \n",
    "    Args:\n",
    "        directory_path: Path to directory containing HTML filings\n",
    "        verbose: Whether to print detailed information during extraction\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing all extracted EPS information\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.html'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            results = extract_eps_from_filing(file_path, verbose=verbose)\n",
    "            value = select_final_eps(results)\n",
    "\n",
    "            all_results.append({ \"filename\": filename,\"eps\": value})\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    df = pd.DataFrame(all_results)\n",
    "    return df\n",
    "def extract_numeric_value(text):\n",
    "    \"\"\"\n",
    "    Extract and normalize a numeric value, handling negative numbers in various formats.\n",
    "    Prioritizes decimal numbers over likely footnote references (small integers).\n",
    "    \n",
    "    Args:\n",
    "        text: Text containing a potential numeric value\n",
    "        \n",
    "    Returns:\n",
    "        Normalized numeric value as a string, or None if no valid number found\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "        \n",
    "    # Clean the text\n",
    "    cleaned_text = text.replace('$', '').replace(',', '').strip()\n",
    "    \n",
    "    # First try to find decimal numbers (more likely to be actual values)\n",
    "    decimal_match = re.search(r'([\\d]+\\.[\\d]+)', cleaned_text)\n",
    "    if decimal_match:\n",
    "        # Found a number with decimal places - likely the real value\n",
    "        \n",
    "        # Check if it's in parentheses (negative)\n",
    "        if (f\"({decimal_match.group(1)})\" in cleaned_text or \n",
    "            f\"( {decimal_match.group(1)} )\" in cleaned_text):\n",
    "            return f\"-{decimal_match.group(1)}\"\n",
    "            \n",
    "        # Check for explicit negative signs\n",
    "        if re.search(r'^\\s*[\\-−–]', cleaned_text):\n",
    "            return f\"-{decimal_match.group(1)}\"\n",
    "            \n",
    "        # Check for opening parenthesis without closing (split across cells)\n",
    "        if cleaned_text.startswith('(') and not cleaned_text.endswith(')'):\n",
    "            return f\"-{decimal_match.group(1)}\"\n",
    "            \n",
    "        return decimal_match.group(1)\n",
    "    \n",
    "    # Handle case where opening parenthesis is present but closing one is missing\n",
    "    if cleaned_text.startswith('(') and not cleaned_text.endswith(')'):\n",
    "        match = re.search(r'\\(?([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle normal parentheses case\n",
    "    if '(' in cleaned_text and ')' in cleaned_text:\n",
    "        # Extract the number inside parentheses\n",
    "        match = re.search(r'\\(([\\d\\.]+)\\)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle numbers with explicit negative signs\n",
    "    if re.search(r'^\\s*[\\-−–]', cleaned_text):  # Handle various dash characters\n",
    "        match = re.search(r'([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Special case for closing parenthesis only - ignore it\n",
    "    if cleaned_text == ')':\n",
    "        return None\n",
    "    \n",
    "    # Look for integers, but filter out likely footnote references\n",
    "    int_matches = re.findall(r'\\b(\\d+)\\b', cleaned_text)\n",
    "    if int_matches:\n",
    "        # Filter out small integers that are likely footnotes\n",
    "        valid_ints = [n for n in int_matches if len(n) > 2 or int(n) > 20]\n",
    "        if valid_ints:\n",
    "            # Return the first valid integer\n",
    "            return valid_ints[0]\n",
    "        \n",
    "        # If only small integers found, return the largest one as a fallback\n",
    "        # (Less likely to be a footnote reference)\n",
    "        if int_matches:\n",
    "            largest = max(int_matches, key=lambda x: int(x))\n",
    "            # Only return if it's part of a longer text (not standalone footnote)\n",
    "            if len(cleaned_text) > len(largest) + 3:\n",
    "                return largest\n",
    "    \n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Training_Filings_test/0000046080-20-000050.html\n",
      "Found EPS pattern in row: reconciliation of net earnings and earnings per share...\n",
      "Checking next row for values...\n",
      "quarter ended\n",
      "Checking next row for values...\n",
      "(all adjustments reported after-tax)march 29, 2020diluted per share amountpro formamarch 31, 2019pro forma diluted per share amount (1)\n",
      "Found value in next row: 29\n",
      "Found value in next row: 31\n",
      "Found value in next row: -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'table_idx': 9,\n",
       "  'row_text': 'reconciliation of net earnings and earnings per share',\n",
       "  'basic': False,\n",
       "  'diluted': True,\n",
       "  'gaap': True,\n",
       "  'value': '29',\n",
       "  'all_values': ['29', '31', '-1']}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process a single file\n",
    "file_path = 'Training_Filings_test/0000046080-20-000050.html'\n",
    "results = extract_eps_from_filing(file_path, verbose=True)\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0.03'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_final_eps(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching text: 'net earnings per share – basic $0.78 $1.23 (36.6)%'\n",
      "Matching text: 'net earnings per share – diluted 0.78 1.23 (36.6)'\n",
      "Matching text: 'shares used to compute earnings per share (000)'\n",
      "Candidate 1: Score 1120, Value: 0.78\n",
      "  Row text: net earnings per share – basic $0.78 $1.23 (36.6)%...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share.*basic\n",
      "Candidate 2: Score 930, Value: 0.78\n",
      "  Row text: net earnings per share – diluted 0.78 1.23 (36.6)...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 3: Score 820, Value: -000\n",
      "  Row text: shares used to compute earnings per share (000)...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: 'earnings (loss) per common share'\n",
      "Matching text: 'gaap net income (loss) and gaap diluted earnings (loss) per share$(10,643) $(0.41) $48,234 $1.84'\n",
      "Matching text: 'non-gaap net income and diluted earnings per share$12,369 $0.47 $71,246 $2.71'\n",
      "Candidate 1: Score 1070, Value: -0.41\n",
      "  Row text: earnings (loss) per common share...\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 380, Value: -10643\n",
      "  Row text: gaap net income (loss) and gaap diluted earnings (loss) per share$(10,643) $(0.4...\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 310, Value: 12369\n",
      "  Row text: non-gaap net income and diluted earnings per share$12,369 $0.47 $71,246 $2.71...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "HERE IN basic\n",
      "Matching text: 'loss per share - basic and diluted$(15.19) $(1.09)'\n",
      "Matching text: 'loss per share reconciliation(1)three months ended'\n",
      "Matching text: 'income (loss) from continuing operations attributable to valaris shares earnings (loss) per share fr'\n",
      "Candidate 1: Score 1420, Value: -15.19\n",
      "  Row text: loss per share - basic and diluted$(15.19) $(1.09)...\n",
      "  Matched pattern: (?:loss|earnings|income)\\s+per\\s+share\\s+[-–]\\s+basic\\s+(?:and|&)\\s+diluted\n",
      "Candidate 2: Score 770, Value: -1\n",
      "  Row text: loss per share reconciliation(1)three months ended...\n",
      "  Matched pattern: loss\\s+per\\s+share\n",
      "Candidate 3: Score 370, Value: -3006.3\n",
      "  Row text: income (loss) from continuing operations attributable to valaris shares earnings...\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n",
      "Matching text: 'non-gaap reconciliation of diluted earnings per share'\n",
      "Matching text: 'diluted earnings per share (“eps”) as reported$0.26  $0.41  $0.46  $0.37  $0.28'\n",
      "Matching text: 'diluted eps excluding merger expenses0.26  0.41  0.46  0.40  0.37'\n",
      "Matching text: 'diluted eps excluding (gain)/loss on investment securities0.25  0.41  0.46  0.40  0.37'\n",
      "Matching text: 'diluted eps excluding death benefit on boli0.24  0.41  0.45  0.39  0.37'\n",
      "Matching text: 'core diluted eps$0.24  $0.41  $0.45  $0.39  $0.37'\n",
      "Matching text: 'basic earnings per share$0.26  $0.41  $0.46  $0.37  $0.28'\n",
      "Matching text: 'diluted earnings per share0.26  0.41  0.46  0.37  0.28'\n",
      "Matching text: 'basic earnings per share$0.26  $0.41  $0.46  $0.37  $0.28'\n",
      "Matching text: 'diluted earnings per share0.26  0.41  0.46  0.37  0.28'\n",
      "Candidate 1: Score 1120, Value: 0.26\n",
      "  Row text: basic earnings per share$0.26  $0.41  $0.46  $0.37  $0.28...\n",
      "  Matched pattern: basic\\s+earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 1120, Value: 0.26\n",
      "  Row text: basic earnings per share$0.26  $0.41  $0.46  $0.37  $0.28...\n",
      "  Matched pattern: basic\\s+earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 830, Value: 0.26\n",
      "  Row text: diluted earnings per share (“eps”) as reported$0.26  $0.41  $0.46  $0.37  $0.28...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: 'earnings per share (unaudited)'\n",
      "Matching text: 'basic earnings per common share\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.47\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.71\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.65'\n",
      "Matching text: 'diluted earnings per common share\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.47\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.71\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.65'\n",
      "Candidate 1: Score 1120, Value: 0.47\n",
      "  Row text: basic earnings per common share\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.47\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.71\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "...\n",
      "  Matched pattern: basic\\s+earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 830, Value: 0.47\n",
      "  Row text: diluted earnings per common share\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.47\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "\n",
      " 0.71\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 770, Value: 31\n",
      "  Row text: earnings per share (unaudited)...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: 'diluted earnings per common share'\n",
      "Matching text: 'net income available to common stockholders per share1$0.74$1.71(57)%'\n",
      "Matching text: 'adjustment made to reconcile net income available to common stockholders per share to core earnings '\n",
      "Matching text: 'core earnings per share$1.34$1.39(4)%'\n",
      "Candidate 1: Score 920, Value: 0.74\n",
      "  Row text: net income available to common stockholders per share1$0.74$1.71(57)%...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 2: Score 920, Value: 0.64\n",
      "  Row text: adjustment made to reconcile net income available to common stockholders per sha...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 3: Score 820, Value: 0.74\n",
      "  Row text: diluted earnings per common share...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: 'gaap net income per share - diluted$2.29  $1.03  122%'\n",
      "Matching text: 'non-gaap net income per share - diluted$2.56  $1.14  125%'\n",
      "Matching text: 'net income per common share'\n",
      "Candidate 1: Score 1020, Value: 2.32\n",
      "  Row text: net income per common share...\n",
      "  Matched pattern: net\\s+income\\s+per\\s+common\\s+share\n",
      "Candidate 2: Score 930, Value: 2.29\n",
      "  Row text: gaap net income per share - diluted$2.29  $1.03  122%...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 3: Score 910, Value: 2.56\n",
      "  Row text: non-gaap net income per share - diluted$2.56  $1.14  125%...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Matching text: '•diluted eps $0.71, up 34% from the first quarter of 2019'\n",
      "Matching text: '•adjusted diluted eps $0.81, up 31% from the first quarter of 2019'\n",
      "Matching text: 'diluted eps$0.71 $0.53'\n",
      "Matching text: 'adjusted diluted eps$0.81 $0.62'\n",
      "Matching text: 'adjusted diluted eps*$2.95 - $3.07'\n",
      "Matching text: 'basic earnings per share'\n",
      "Matching text: 'diluted earnings per share'\n",
      "Matching text: 'adjusted diluted eps'\n",
      "Candidate 1: Score 1020, Value: 0.71\n",
      "  Row text: basic earnings per share...\n",
      "  Matched pattern: basic\\s+earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 820, Value: 0.71\n",
      "  Row text: diluted earnings per share...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 170, Value: 0.81\n",
      "  Row text: adjusted diluted eps...\n",
      "  Matched pattern: adjusted\n",
      "HERE IN basic\n",
      "Matching text: 'basic and diluted loss per share'\n",
      "Matching text: 'non-gaap diluted (loss) earnings per share from continuing operations attributable to controlling in'\n",
      "Candidate 1: Score 1420, Value: -0.57\n",
      "  Row text: basic and diluted loss per share...\n",
      "  Matched pattern: basic\\s+(?:and|&)\\s+diluted\\s+(?:loss|earnings|income)\\s+per\\s+share\n",
      "Candidate 2: Score 960, Value: -0.14\n",
      "  Row text: non-gaap diluted (loss) earnings per share from continuing operations attributab...\n",
      "  Matched pattern: \\(loss\\)\\s*earnings\\s*per\\s+(?:common\\s+)?share\n",
      "Matching text: '•\n",
      "\n",
      "\n",
      "net income of $5.05 million and eps of $0.60'\n",
      "Matching text: '•\n",
      "\n",
      "\n",
      "net income for the first six months of fiscal 2020 was $11.70 million compared to $11.73 million'\n",
      "Matching text: '•\n",
      "\n",
      "\n",
      "net income (after a $2.00 million provision for loan losses) was $5.05 million for the current q'\n",
      "Matching text: 'net income per common share'\n",
      "Matching text: 'net income per common share'\n",
      "Candidate 1: Score 1020, Value: 0.61\n",
      "  Row text: net income per common share...\n",
      "  Matched pattern: net\\s+income\\s+per\\s+common\\s+share\n",
      "Candidate 2: Score 1020, Value: 1.40\n",
      "  Row text: net income per common share...\n",
      "  Matched pattern: net\\s+income\\s+per\\s+common\\s+share\n",
      "Candidate 3: Score 140, Value: 5.05\n",
      "  Row text: •\n",
      "\n",
      "\n",
      "net income of $5.05 million and eps of $0.60...\n",
      "  Matched pattern: eps\n",
      "Found 1 rows with identical text and score: 'net income per common share...'\n",
      "Matching text: 'net income per share attributable to uct common stockholders'\n",
      "Matching text: 'shares used in computing net income per share'\n",
      "Candidate 1: Score 1020, Value: 0.24\n",
      "  Row text: net income per share attributable to uct common stockholders...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 2: Score 420, Value: 39817\n",
      "  Row text: shares used in computing net income per share...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Matching text: 'basic income (loss) per share$(0.16) $0.76'\n",
      "Matching text: 'diluted income (loss) per share$(0.16) $0.76'\n",
      "Matching text: 'net income (loss) per share (diluted)$(0.16) $0.76 — — $(0.10)'\n",
      "Matching text: 'net income (loss) per share (diluted)$(0.16) $0.25 $0.09 $0.76 $(0.10) $0.14 $0.80'\n",
      "Candidate 1: Score 930, Value: -0.16\n",
      "  Row text: net income (loss) per share (diluted)$(0.16) $0.76 — — $(0.10)...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 2: Score 930, Value: -0.16\n",
      "  Row text: net income (loss) per share (diluted)$(0.16) $0.25 $0.09 $0.76 $(0.10) $0.14 $0....\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 3: Score 920, Value: -0.16\n",
      "  Row text: basic income (loss) per share$(0.16) $0.76...\n",
      "  Matched pattern: income.*per\\s+share\n",
      "Matching text: 'basic net income per share attributable to innoviva stockholders \n",
      "$0.65  \n",
      "$0.33'\n",
      "Matching text: 'diluted net income per share attributable to innoviva stockholders \n",
      "$0.59  \n",
      "$0.31'\n",
      "Matching text: 'shares used to compute basic net income per share \n",
      " 101,235  \n",
      " 101,059'\n",
      "Matching text: 'shares used to compute diluted net income per share \n",
      " 113,509  \n",
      " 113,376'\n",
      "Candidate 1: Score 1220, Value: 0.65\n",
      "  Row text: basic net income per share attributable to innoviva stockholders \n",
      "$0.65  \n",
      "$0.33...\n",
      "  Matched pattern: basic.*net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 2: Score 930, Value: 0.59\n",
      "  Row text: diluted net income per share attributable to innoviva stockholders \n",
      "$0.59  \n",
      "$0.3...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 3: Score 620, Value: 101235\n",
      "  Row text: shares used to compute basic net income per share \n",
      " 101,235  \n",
      " 101,059...\n",
      "  Matched pattern: basic.*net\\s+(?:income|earnings).*per\\s+share\n",
      "Matching text: '·eps $0.66; adjusted eps $0.73'\n",
      "Matching text: 'eps \n",
      "$0.66  \n",
      "$1.00  \n",
      " (34%) \n",
      "$1.51  \n",
      "$1.74  \n",
      " (13%)'\n",
      "Matching text: 'adjusted eps \n",
      "$0.73  \n",
      "$0.70  \n",
      " 4% \n",
      "$1.57  \n",
      "$1.40  \n",
      " 12%'\n",
      "Matching text: 'earnings per share attributable\n",
      "    to tetra tech'\n",
      "Candidate 1: Score 920, Value: 0.67\n",
      "  Row text: earnings per share attributable\n",
      "    to tetra tech...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 150, Value: 0.66\n",
      "  Row text: ·eps $0.66; adjusted eps $0.73...\n",
      "  Matched pattern: adjusted\n",
      "Candidate 3: Score 150, Value: 0.73\n",
      "  Row text: adjusted eps \n",
      "$0.73  \n",
      "$0.70  \n",
      " 4% \n",
      "$1.57  \n",
      "$1.40  \n",
      " 12%...\n",
      "  Matched pattern: adjusted\n",
      "Matching text: 'income (loss) per share—basic \n",
      "$3.17  \n",
      " (1.19)'\n",
      "Matching text: 'income (loss) per share—diluted \n",
      "$3.17  \n",
      " (1.19)'\n",
      "Candidate 1: Score 920, Value: 3.17\n",
      "  Row text: income (loss) per share—basic \n",
      "$3.17  \n",
      " (1.19)...\n",
      "  Matched pattern: income.*per\\s+share\n",
      "Candidate 2: Score 830, Value: 3.17\n",
      "  Row text: income (loss) per share—diluted \n",
      "$3.17  \n",
      " (1.19)...\n",
      "  Matched pattern: income.*per\\s+share\n",
      "Matching text: 'net earnings per common share'\n",
      "Matching text: 'net earnings per common share - basic\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.38\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.54'\n",
      "Matching text: 'net earnings per common share - diluted\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.38\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.53'\n",
      "Matching text: 'diluted earnings per share from continuing operations'\n",
      "Matching text: 'gaap diluted earnings per share from continuing operations\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.42\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.57'\n",
      "Matching text: 'non-gaap diluted earnings per share from continuing operations\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.43\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.57'\n",
      "Candidate 1: Score 1120, Value: 0.38\n",
      "  Row text: net earnings per common share - basic\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.38\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.54...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share.*basic\n",
      "Candidate 2: Score 920, Value: 0.43\n",
      "  Row text: net earnings per common share...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 830, Value: 0.38\n",
      "  Row text: net earnings per common share - diluted\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.38\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "\n",
      "0.53...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: '•first-quarter net income of $1.7 billion, or diluted earnings per share (eps) of $1.68'\n",
      "Matching text: '•first-quarter adjusted net income of $1.8 billion, or adjusted diluted eps of $1.83'\n",
      "Matching text: 'diluted eps $1.68 $1.80 (7)% (5)%'\n",
      "Matching text: 'adjusted diluted eps $1.83 $1.78 3% 6%'\n",
      "Matching text: 'basic earnings per share $1.68 $1.81'\n",
      "Matching text: 'diluted earnings per share $1.68 $1.80'\n",
      "Matching text: 'operating expenses operating margin other income (expense) effective income tax rate  net income  di'\n",
      "Matching text: 'operating expenses operating margin other income (expense) effective income tax rate  net income  di'\n",
      "Matching text: 'net revenue  operating expenses operating margin effective income tax rate  net income  diluted earn'\n",
      "Candidate 1: Score 1120, Value: 1.68\n",
      "  Row text: basic earnings per share $1.68 $1.81...\n",
      "  Matched pattern: basic\\s+earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 930, Value: 1.7\n",
      "  Row text: •first-quarter net income of $1.7 billion, or diluted earnings per share (eps) o...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 3: Score 830, Value: 1.68\n",
      "  Row text: diluted earnings per share $1.68 $1.80...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: 'diluted earnings per share\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.56 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.48 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17 \n",
      "\n",
      "\n",
      " %'\n",
      "Matching text: 'earnings per common share'\n",
      "Matching text: 'shares used in the computation of earnings per common share'\n",
      "Matching text: 'adjusted diluted earnings per share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.56 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.50 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13 \n",
      "\n",
      "\n",
      " %'\n",
      "Candidate 1: Score 920, Value: 0.57\n",
      "  Row text: earnings per common share...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 830, Value: 0.56\n",
      "  Row text: diluted earnings per share\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.56 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.48 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 810, Value: 0.56\n",
      "  Row text: adjusted diluted earnings per share\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.56 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.50 ...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: 'basic net income per share \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.11 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.09 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.12 \n",
      "\n",
      "\n",
      " '\n",
      "Matching text: 'diluted net income per share \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.11 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.09 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.12 \n",
      "\n",
      "'\n",
      "Matching text: 'surmodics, inc., and subsidiaries \n",
      " net income and diluted eps gaap to non-gaap reconciliation \n",
      " (in'\n",
      "Matching text: 'total \n",
      "                        revenue \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " operating \n",
      "                        (loss) \n",
      "        '\n",
      "Matching text: 'total \n",
      "                        revenue \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " operating \n",
      "                        income \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "'\n",
      "Matching text: 'surmodics, inc., and subsidiaries \n",
      " net income and diluted eps gaap to non-gaap reconciliation – con'\n",
      "Matching text: 'total \n",
      "                        revenue \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " operating \n",
      "                        (loss) \n",
      "  '\n",
      "Matching text: 'total \n",
      "                        revenue \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " operating \n",
      "                        income \n",
      "\n",
      "\n",
      "'\n",
      "Candidate 1: Score 1220, Value: 0.11\n",
      "  Row text: basic net income per share \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.11 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.09 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "  ...\n",
      "  Matched pattern: basic.*net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 2: Score 930, Value: 0.11\n",
      "  Row text: diluted net income per share \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.11 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " $ \n",
      "\n",
      "\n",
      " 0.09 \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      "...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 3: Score 130, Value: -6\n",
      "  Row text: total \n",
      "                        revenue \n",
      "\n",
      "\n",
      "   \n",
      "\n",
      "\n",
      " operating \n",
      "                    ...\n",
      "  Matched pattern: None\n",
      "Matching text: 'earnings per share'\n",
      "Matching text: 'economic eps$0.50  $0.64  $0.49'\n",
      "Matching text: 'economic eps$0.50  $0.64  $0.49'\n",
      "Candidate 1: Score 920, Value: 0.13\n",
      "  Row text: earnings per share...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 140, Value: 0.50\n",
      "  Row text: economic eps$0.50  $0.64  $0.49...\n",
      "  Matched pattern: eps\n",
      "Candidate 3: Score 140, Value: 0.50\n",
      "  Row text: economic eps$0.50  $0.64  $0.49...\n",
      "  Matched pattern: eps\n",
      "Matching text: '\n",
      " \n",
      " record diluted eps of $1.96, up 41% from $1.39'\n",
      "Matching text: 'net income per common share'\n",
      "Candidate 1: Score 1020, Value: 2.01\n",
      "  Row text: net income per common share...\n",
      "  Matched pattern: net\\s+income\\s+per\\s+common\\s+share\n",
      "Candidate 2: Score 150, Value: 1.96\n",
      "  Row text: \n",
      " \n",
      " record diluted eps of $1.96, up 41% from $1.39...\n",
      "  Matched pattern: eps\n",
      "HERE IN basic\n",
      "Matching text: 'basic and diluted earnings per share\n",
      "  \n",
      " \n",
      "0.30\n",
      " \n",
      " \n",
      " \n",
      "0.35\n",
      " \n",
      " \n",
      " \n",
      "0.33\n",
      " \n",
      " \n",
      " \n",
      "0.31\n",
      " \n",
      " \n",
      " \n",
      "0.30'\n",
      "Matching text: 'diluted eps excluding acquisition costs\n",
      "  \n",
      "$\n",
      "0.34\n",
      " \n",
      "  \n",
      "$\n",
      "0.35\n",
      " \n",
      "  \n",
      "$\n",
      "0.33\n",
      " \n",
      "  \n",
      "$\n",
      "0.31\n",
      " \n",
      " \n",
      "$\n",
      "0.30'\n",
      "Candidate 1: Score 1420, Value: 0.30\n",
      "  Row text: basic and diluted earnings per share\n",
      "  \n",
      " \n",
      "0.30\n",
      " \n",
      " \n",
      " \n",
      "0.35\n",
      " \n",
      " \n",
      " \n",
      "0.33\n",
      " \n",
      " \n",
      " \n",
      "0.31\n",
      "...\n",
      "  Matched pattern: basic\\s+(?:and|&)\\s+diluted\\s+(?:loss|earnings|income)\\s+per\\s+share\n",
      "Candidate 2: Score 150, Value: 0.34\n",
      "  Row text: diluted eps excluding acquisition costs\n",
      "  \n",
      "$\n",
      "0.34\n",
      " \n",
      "  \n",
      "$\n",
      "0.35\n",
      " \n",
      "  \n",
      "$\n",
      "0.33\n",
      " \n",
      "  \n",
      "$...\n",
      "  Matched pattern: eps\n",
      "Matching text: '\n",
      " \n",
      " diluted earnings per share was $1.40 and increased 23%'\n",
      "Matching text: '($ in millions, except per share amounts)\n",
      " \n",
      "  \n",
      "   revenue  \n",
      " \n",
      " \n",
      "  \n",
      "\n",
      "  operating    income  \n",
      " \n",
      " \n",
      "  \n",
      "\n",
      "'\n",
      "Matching text: 'earnings per share'\n",
      "Candidate 1: Score 920, Value: 1.41\n",
      "  Row text: earnings per share...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 830, Value: 1.40\n",
      "  Row text: \n",
      " \n",
      " diluted earnings per share was $1.40 and increased 23%...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score -455, Value: 2019\n",
      "  Row text: ($ in millions, except per share amounts)\n",
      " \n",
      "  \n",
      "   revenue  \n",
      " \n",
      " \n",
      "  \n",
      "\n",
      "  operating ...\n",
      "  Matched pattern: per\\s+share\n",
      "Matching text: 'net income per common share'\n",
      "Matching text: 'reconciliation of earnings per share to ffo per share'\n",
      "Matching text: 'net income per common sharediluted\n",
      "  \n",
      "$\n",
      " 1.51 \n",
      "\n",
      "  \n",
      "$\n",
      " 0.96'\n",
      "Candidate 1: Score 1020, Value: 1.52\n",
      "  Row text: net income per common share...\n",
      "  Matched pattern: net\\s+income\\s+per\\s+common\\s+share\n",
      "Candidate 2: Score 930, Value: 1.51\n",
      "  Row text: net income per common sharediluted\n",
      "  \n",
      "$\n",
      " 1.51 \n",
      "\n",
      "  \n",
      "$\n",
      " 0.96...\n",
      "  Matched pattern: net\\s+income\\s+per\\s+common\\s+share\n",
      "Candidate 3: Score 830, Value: 1.51\n",
      "  Row text: reconciliation of earnings per share to ffo per share...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "HERE IN basic\n",
      "Matching text: 'basic and diluted net (loss) income per share$(0.24)$0.04'\n",
      "Matching text: '(b) an adjustment of $771 to cost of revenue, identified in the fourth quarter of 2018, has been ref'\n",
      "Candidate 1: Score 920, Value: -0.24\n",
      "  Row text: basic and diluted net (loss) income per share$(0.24)$0.04...\n",
      "  Matched pattern: income.*per\\s+share\n",
      "Candidate 2: Score -100, Value: -771\n",
      "  Row text: (b) an adjustment of $771 to cost of revenue, identified in the fourth quarter o...\n",
      "  Matched pattern: None\n",
      "Matching text: 'diluted eps$0.91 $0.63 44.4%'\n",
      "Matching text: 'adjusted eps (non-gaap)1$0.94 $0.84 11.9%'\n",
      "Matching text: 'adjusted eps (non-gaap)$0.94 $0.84 $2.31 $2.07'\n",
      "Candidate 1: Score 150, Value: 0.91\n",
      "  Row text: diluted eps$0.91 $0.63 44.4%...\n",
      "  Matched pattern: eps\n",
      "Candidate 2: Score 150, Value: 1\n",
      "  Row text: adjusted eps (non-gaap)1$0.94 $0.84 11.9%...\n",
      "  Matched pattern: adjusted\n",
      "Candidate 3: Score 150, Value: 0.94\n",
      "  Row text: adjusted eps (non-gaap)$0.94 $0.84 $2.31 $2.07...\n",
      "  Matched pattern: adjusted\n",
      "HERE IN basic\n",
      "HERE IN basic\n",
      "Matching text: 'basic and diluted net loss per share\n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "(0.42)\n",
      "\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "(0.15)'\n",
      "Matching text: 'reconciliation of non-gaap adjusted loss per share'\n",
      "Matching text: 'basic and diluted adjusted net loss per share\n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "(0.36)\n",
      "\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "(0.20)'\n",
      "Candidate 1: Score 870, Value: -0.42\n",
      "  Row text: basic and diluted net loss per share\n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "(0.42)\n",
      "\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "(0.15)...\n",
      "  Matched pattern: basic.*loss\\s+per\\s+share\n",
      "Candidate 2: Score 850, Value: -0.36\n",
      "  Row text: basic and diluted adjusted net loss per share\n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "(0.36)\n",
      "\t\t\t\t\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t \n",
      "\n",
      "\n",
      "\n",
      "$\n",
      "\n",
      "...\n",
      "  Matched pattern: basic.*loss\\s+per\\s+share\n",
      "Candidate 3: Score 720, Value: 31\n",
      "  Row text: reconciliation of non-gaap adjusted loss per share...\n",
      "  Matched pattern: loss\\s+per\\s+share\n",
      "HERE IN basic\n",
      "Matching text: 'net income (loss) per share - basic$0.25 $(0.01)'\n",
      "Matching text: 'net income (loss) per share - diluted$0.24 $(0.01)'\n",
      "Matching text: 'net income (loss) per share - basic and diluted'\n",
      "Matching text: 'gaap net income (loss) per share - basic$0.25 $(0.01)'\n",
      "Matching text: 'gaap net income (loss) per share - diluted$0.24 $(0.01)'\n",
      "Matching text: 'non-gaap net income per share - basic$1.09 $0.71'\n",
      "Matching text: 'non-gaap net income per share - diluted$1.05 $0.67'\n",
      "Candidate 1: Score 1120, Value: 0.25\n",
      "  Row text: net income (loss) per share - basic$0.25 $(0.01)...\n",
      "  Matched pattern: net\\s+income.*per\\s+(?:common\\s+)?share.*basic\n",
      "Candidate 2: Score 1120, Value: 0.25\n",
      "  Row text: net income (loss) per share - basic and diluted...\n",
      "  Matched pattern: net\\s+income.*per\\s+(?:common\\s+)?share.*basic\n",
      "Candidate 3: Score 1120, Value: 0.25\n",
      "  Row text: gaap net income (loss) per share - basic$0.25 $(0.01)...\n",
      "  Matched pattern: net\\s+income.*per\\s+(?:common\\s+)?share.*basic\n",
      "Matching text: '•$(3.61) comprehensive loss per common share, comprised of'\n",
      "Matching text: '◦$(4.46) net loss per common share'\n",
      "Matching text: 'ending cumulative non-deductible net capital loss per common share$0.75 $0.73 $0.97 $0.89 $0.32'\n",
      "Candidate 1: Score 120, Value: -3.61\n",
      "  Row text: •$(3.61) comprehensive loss per common share, comprised of...\n",
      "  Matched pattern: None\n",
      "Candidate 2: Score 120, Value: -4.46\n",
      "  Row text: ◦$(4.46) net loss per common share...\n",
      "  Matched pattern: None\n",
      "Candidate 3: Score 120, Value: 0.75\n",
      "  Row text: ending cumulative non-deductible net capital loss per common share$0.75 $0.73 $0...\n",
      "  Matched pattern: None\n",
      "Matching text: 'earnings per share - basic$0.21  $0.74  (72)%$0.86  (76)%'\n",
      "Matching text: 'earnings per share - diluted$0.21  $0.73  (71) $0.85  (75)'\n",
      "Matching text: 'earnings per share - basic$0.21  $0.74  (72)%$0.86  (76)%'\n",
      "Matching text: 'earnings per share - diluted0.21  0.73  (71) 0.85  (75)'\n",
      "Candidate 1: Score 1120, Value: 0.21\n",
      "  Row text: earnings per share - basic$0.21  $0.74  (72)%$0.86  (76)%...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share.*basic\n",
      "Candidate 2: Score 1120, Value: 0.21\n",
      "  Row text: earnings per share - basic$0.21  $0.74  (72)%$0.86  (76)%...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share.*basic\n",
      "Candidate 3: Score 830, Value: 0.21\n",
      "  Row text: earnings per share - diluted$0.21  $0.73  (71) $0.85  (75)...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: '(loss) earnings per share'\n",
      "Matching text: 'adjusted diluted earnings per share'\n",
      "Matching text: 'adjusted diluted earnings per share\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.10\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.40\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.34\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.40\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "'\n",
      "Candidate 1: Score 1070, Value: -3.15\n",
      "  Row text: (loss) earnings per share...\n",
      "  Matched pattern: \\(loss\\)\\s*earnings\\s*per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 810, Value: 0.10\n",
      "  Row text: adjusted diluted earnings per share\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.10\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.40\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.34\n",
      "\n",
      " ...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 230, Value: 126630446\n",
      "  Row text: adjusted diluted earnings per share...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "HERE IN basic\n",
      "HERE IN basic\n",
      "HERE IN basic\n",
      "HERE IN basic\n",
      "HERE IN basic\n",
      "Matching text: '•\n",
      "\n",
      "net loss according to generally accepted accounting principles in the u.s. (gaap) was $38.7 milli'\n",
      "Matching text: '•\n",
      "\n",
      "non-gaap net income was $1.7 million for the quarter, or a non-gaap basic and diluted earnings pe'\n",
      "Matching text: '(loss) earnings per share'\n",
      "Matching text: 'gaap loss per share — basic and diluted\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "(0.24\n",
      "\n",
      ")\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "(0.62\n",
      "\n",
      ")'\n",
      "Matching text: 'non-gaap earnings (loss) per share — basic and diluted\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.01\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "(0.17\n",
      "\n",
      ")'\n",
      "Candidate 1: Score 1070, Value: -0.24\n",
      "  Row text: (loss) earnings per share...\n",
      "  Matched pattern: \\(loss\\)\\s*earnings\\s*per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 1050, Value: 0.01\n",
      "  Row text: non-gaap earnings (loss) per share — basic and diluted\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.01\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "(0....\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 870, Value: -0.24\n",
      "  Row text: gaap loss per share — basic and diluted\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "(0.24\n",
      "\n",
      ")\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "(0.62\n",
      "\n",
      ")...\n",
      "  Matched pattern: loss\\s+per\\s+share\n",
      "Matching text: 'basic earnings per share\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.08\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.86'\n",
      "Matching text: 'diluted earnings per share\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.06\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.85'\n",
      "Candidate 1: Score 1120, Value: 1.08\n",
      "  Row text: basic earnings per share\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.08\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.86...\n",
      "  Matched pattern: basic\\s+earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 830, Value: 1.06\n",
      "  Row text: diluted earnings per share\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.06\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.85...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: 'earnings per share'\n",
      "Matching text: 'earnings per share-diluted (gaap)\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.99\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.82\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "2.09\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "3.33'\n",
      "Matching text: 'adjusted earnings per share-diluted (non-gaap)\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.25\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.82\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "2.35\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "3'\n",
      "Candidate 1: Score 920, Value: 1.00\n",
      "  Row text: earnings per share...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 830, Value: 0.99\n",
      "  Row text: earnings per share-diluted (gaap)\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.99\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.82\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "2.09\n",
      "\n",
      " \n",
      "\n",
      "...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 810, Value: 1.25\n",
      "  Row text: adjusted earnings per share-diluted (non-gaap)\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.25\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "1.82\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Matching text: 'basic earnings (loss) per share\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.08\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.65\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.67\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.59\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "('\n",
      "Matching text: 'diluted earnings (loss) per share\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.08\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.64\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.66\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.58\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "'\n",
      "Matching text: 'basic earnings (loss) per share\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.08\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "(0.26\n",
      "\n",
      ")'\n",
      "Matching text: 'diluted earnings (loss) per share\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.08\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "(0.26\n",
      "\n",
      ")'\n",
      "Candidate 1: Score 1070, Value: 0.08\n",
      "  Row text: basic earnings (loss) per share\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.08\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.65\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.67\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "...\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 1070, Value: 0.08\n",
      "  Row text: basic earnings (loss) per share\n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "0.08\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "$\n",
      "\n",
      "(0.26\n",
      "\n",
      ")...\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 980, Value: 0.08\n",
      "  Row text: diluted earnings (loss) per share\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.08\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.64\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "0.66\n",
      "\n",
      " \n",
      "\n",
      "...\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n",
      "Matching text: 'basic earnings per share$                    \n",
      " 2.00\n",
      "$                 1.15\n",
      "$                 3.89\n",
      "$ '\n",
      "Matching text: 'diluted earnings per\n",
      "share$                      1.94\n",
      "$                 1.10\n",
      "$                 3.76\n",
      "'\n",
      "Matching text: 'shares used in computing earnings per share'\n",
      "Matching text: 'gaap diluted earnings per share$     1.94\n",
      "$     1.10\n",
      "$       3.76\n",
      "$     2.42'\n",
      "Matching text: 'non-gaap diluted earnings per share$     2.14\n",
      "$     1.56\n",
      "$       3.94\n",
      "$     3.01'\n",
      "Candidate 1: Score 1120, Value: 2.00\n",
      "  Row text: basic earnings per share$                    \n",
      " 2.00\n",
      "$                 1.15\n",
      "$    ...\n",
      "  Matched pattern: basic\\s+earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 830, Value: 1.94\n",
      "  Row text: diluted earnings per\n",
      "share$                      1.94\n",
      "$                 1.10\n",
      "$  ...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 830, Value: 1.94\n",
      "  Row text: gaap diluted earnings per share$     1.94\n",
      "$     1.10\n",
      "$       3.76\n",
      "$     2.42...\n",
      "  Matched pattern: earnings\\s+per\\s+(?:common\\s+)?share\n",
      "HERE IN basic\n",
      "Matching text: 'adjusted net income per share'\n",
      "Matching text: 'basic number of shares - basic eps basis64,336,777  61,691,001'\n",
      "Matching text: 'diluted number of shares - diluted eps basis66,041,296  62,125,582'\n",
      "Candidate 1: Score 1020, Value: 0.62\n",
      "  Row text: adjusted net income per share...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 2: Score -360, Value: 64336777\n",
      "  Row text: basic number of shares - basic eps basis64,336,777  61,691,001...\n",
      "  Matched pattern: eps\n",
      "Candidate 3: Score -450, Value: 66041296\n",
      "  Row text: diluted number of shares - diluted eps basis66,041,296  62,125,582...\n",
      "  Matched pattern: eps\n",
      "HERE IN basic\n",
      "HERE IN basic\n",
      "Matching text: 'basic and diluted net income per share'\n",
      "Matching text: 'net income per share—basic $0.42 $2.14'\n",
      "Matching text: 'net income per share—diluted$0.42 $2.14'\n",
      "Matching text: 'adjusted basic net income per share$0.39 $2.30'\n",
      "Matching text: 'adjusted diluted net income per share$0.39 $2.30'\n",
      "Candidate 1: Score 1220, Value: 0.42\n",
      "  Row text: basic and diluted net income per share...\n",
      "  Matched pattern: basic.*net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 2: Score 1200, Value: 0.39\n",
      "  Row text: adjusted basic net income per share$0.39 $2.30...\n",
      "  Matched pattern: basic.*net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 3: Score 1120, Value: 0.42\n",
      "  Row text: net income per share—basic $0.42 $2.14...\n",
      "  Matched pattern: net\\s+income.*per\\s+(?:common\\s+)?share.*basic\n",
      "Matching text: 'earnings per ordinary share'\n",
      "Matching text: 'diluted earnings per ordinary share'\n",
      "Matching text: 'diluted earnings per ordinary share - as reported$0.11'\n",
      "Matching text: 'diluted earnings per ordinary share - as adjusted$0.34'\n",
      "Matching text: 'diluted earnings per ordinary share - pro forma adjusted'\n",
      "Matching text: 'diluted earnings per ordinary share - pro forma$0.32  $0.35  $0.35  $0.27  $1.29'\n",
      "Matching text: 'diluted earnings per ordinary share - as adjusted$0.39  $0.44  $0.49  $0.47  $1.78'\n",
      "Candidate 1: Score 220, Value: 0.11\n",
      "  Row text: earnings per ordinary share...\n",
      "  Matched pattern: None\n",
      "Candidate 2: Score 180, Value: 0.32\n",
      "  Row text: diluted earnings per ordinary share - pro forma adjusted...\n",
      "  Matched pattern: adjusted\n",
      "Candidate 3: Score 160, Value: 0.34\n",
      "  Row text: diluted earnings per ordinary share - as adjusted$0.34...\n",
      "  Matched pattern: adjusted\n",
      "Matching text: '•diluted gaap eps $0.05; adjusted eps $0.17, increase of 64%'\n",
      "Matching text: 'earnings (loss) per share'\n",
      "Matching text: 'diluted earnings (loss) per share (gaap)$0.05 $(0.59)'\n",
      "Matching text: 'fully diluted earnings (loss) per share (non-gaap)0.07 (0.01)'\n",
      "Matching text: 'adjusted eps (non-gaap)$0.17 $0.11'\n",
      "Matching text: 'share count for adjusted eps (non-gaap)642.7 642.7'\n",
      "Matching text: '*adjusted eps reflects the share count of 642.7, the proforma fully diluted share count that was det'\n",
      "Candidate 1: Score 1070, Value: 0.05\n",
      "  Row text: earnings (loss) per share...\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n",
      "Candidate 2: Score 980, Value: 0.05\n",
      "  Row text: diluted earnings (loss) per share (gaap)$0.05 $(0.59)...\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n",
      "Candidate 3: Score 960, Value: 0.07\n",
      "  Row text: fully diluted earnings (loss) per share (non-gaap)0.07 (0.01)...\n",
      "  Matched pattern: earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eps",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7a29b67d-7624-4769-bb86-5562df7cbe1c",
       "rows": [
        [
         "0",
         "0000004977-20-000054.html",
         "0.78"
        ],
        [
         "1",
         "0000008947-20-000044.html",
         "-0.41"
        ],
        [
         "2",
         "0000046080-20-000050.html",
         "29"
        ],
        [
         "3",
         "0000066570-20-000013.html",
         "1.12"
        ],
        [
         "4",
         "0000314808-20-000062.html",
         "-15.19"
        ],
        [
         "5",
         "0000706129-20-000012.html",
         "0.26"
        ],
        [
         "6",
         "0000846617-20-000024.html",
         "0.47"
        ],
        [
         "7",
         "0000874766-20-000033.html",
         "0.74"
        ],
        [
         "8",
         "0000875320-20-000014.html",
         "2.32"
        ],
        [
         "9",
         "0000892537-20-000010.html",
         "0.71"
        ],
        [
         "10",
         "0000895419-20-000042.html",
         "-0.57"
        ],
        [
         "11",
         "0000939057-20-000186.html",
         "2.01"
        ],
        [
         "12",
         "0000950103-20-008424.html",
         "0.24"
        ],
        [
         "13",
         "0001008654-20-000048.html",
         "-0.16"
        ],
        [
         "14",
         "0001104659-20-052683.html",
         "-0.42"
        ],
        [
         "15",
         "0001104659-20-052792.html",
         "-0.03"
        ],
        [
         "16",
         "0001104659-20-053353.html",
         "0.65"
        ],
        [
         "17",
         "0001104659-20-053534.html",
         "0.67"
        ],
        [
         "18",
         "0001104659-20-053563.html",
         "3.17"
        ],
        [
         "19",
         "0001140361-20-010070.html",
         "0.38"
        ],
        [
         "20",
         "0001141391-20-000089.html",
         "1.68"
        ],
        [
         "21",
         "0001157523-20-000597.html",
         "-0.03"
        ],
        [
         "22",
         "0001157523-20-000599.html",
         "0.57"
        ],
        [
         "23",
         "0001157523-20-000600.html",
         "0.11"
        ],
        [
         "24",
         "0001165002-20-000083.html",
         "0.13"
        ],
        [
         "25",
         "0001171843-20-003035.html",
         "-6.79"
        ],
        [
         "26",
         "0001193125-20-124288.html",
         "2.01"
        ],
        [
         "27",
         "0001193125-20-124568.html",
         "0.30"
        ],
        [
         "28",
         "0001193125-20-126089.html",
         "1.41"
        ],
        [
         "29",
         "0001193125-20-126683.html",
         "1.52"
        ],
        [
         "30",
         "0001289945-20-000036.html",
         "-0.24"
        ],
        [
         "31",
         "0001299709-20-000078.html",
         "0.91"
        ],
        [
         "32",
         "0001323885-20-000027.html",
         "-0.42"
        ],
        [
         "33",
         "0001373715-20-000098.html",
         "0.25"
        ],
        [
         "34",
         "0001423689-20-000040.html",
         "-3.61"
        ],
        [
         "35",
         "0001436425-20-000011.html",
         "0.21"
        ],
        [
         "36",
         "0001538263-20-000014.html",
         "-1"
        ],
        [
         "37",
         "0001564590-20-019396.html",
         "-3.15"
        ],
        [
         "38",
         "0001564590-20-019421.html",
         "-0.24"
        ],
        [
         "39",
         "0001564590-20-019431.html",
         "1.08"
        ],
        [
         "40",
         "0001564590-20-019442.html",
         "1.00"
        ],
        [
         "41",
         "0001564590-20-019726.html",
         "0.08"
        ],
        [
         "42",
         "0001564590-20-019755.html",
         "2.00"
        ],
        [
         "43",
         "0001564590-20-019760.html",
         "-2.21"
        ],
        [
         "44",
         "0001576427-20-000032.html",
         "0.62"
        ],
        [
         "45",
         "0001620459-20-000067.html",
         "-1.21"
        ],
        [
         "46",
         "0001678463-20-000062.html",
         "-0.22"
        ],
        [
         "47",
         "0001691303-20-000019.html",
         "0.42"
        ],
        [
         "48",
         "0001720635-20-000018.html",
         "0.11"
        ],
        [
         "49",
         "0001722482-20-000089.html",
         "0.05"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 50
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>eps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000004977-20-000054.html</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000008947-20-000044.html</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000046080-20-000050.html</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000066570-20-000013.html</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000314808-20-000062.html</td>\n",
       "      <td>-15.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000706129-20-000012.html</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000846617-20-000024.html</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000874766-20-000033.html</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0000875320-20-000014.html</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0000892537-20-000010.html</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0000895419-20-000042.html</td>\n",
       "      <td>-0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0000939057-20-000186.html</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0000950103-20-008424.html</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0001008654-20-000048.html</td>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0001104659-20-052683.html</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0001104659-20-052792.html</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0001104659-20-053353.html</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0001104659-20-053534.html</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0001104659-20-053563.html</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0001140361-20-010070.html</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0001141391-20-000089.html</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0001157523-20-000597.html</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0001157523-20-000599.html</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0001157523-20-000600.html</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0001165002-20-000083.html</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0001171843-20-003035.html</td>\n",
       "      <td>-6.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0001193125-20-124288.html</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0001193125-20-124568.html</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0001193125-20-126089.html</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0001193125-20-126683.html</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0001289945-20-000036.html</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0001299709-20-000078.html</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0001323885-20-000027.html</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0001373715-20-000098.html</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0001423689-20-000040.html</td>\n",
       "      <td>-3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0001436425-20-000011.html</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0001538263-20-000014.html</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0001564590-20-019396.html</td>\n",
       "      <td>-3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0001564590-20-019421.html</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0001564590-20-019431.html</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0001564590-20-019442.html</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0001564590-20-019726.html</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0001564590-20-019755.html</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0001564590-20-019760.html</td>\n",
       "      <td>-2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0001576427-20-000032.html</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0001620459-20-000067.html</td>\n",
       "      <td>-1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0001678463-20-000062.html</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0001691303-20-000019.html</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0001720635-20-000018.html</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0001722482-20-000089.html</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filename     eps\n",
       "0   0000004977-20-000054.html    0.78\n",
       "1   0000008947-20-000044.html   -0.41\n",
       "2   0000046080-20-000050.html      29\n",
       "3   0000066570-20-000013.html    1.12\n",
       "4   0000314808-20-000062.html  -15.19\n",
       "5   0000706129-20-000012.html    0.26\n",
       "6   0000846617-20-000024.html    0.47\n",
       "7   0000874766-20-000033.html    0.74\n",
       "8   0000875320-20-000014.html    2.32\n",
       "9   0000892537-20-000010.html    0.71\n",
       "10  0000895419-20-000042.html   -0.57\n",
       "11  0000939057-20-000186.html    2.01\n",
       "12  0000950103-20-008424.html    0.24\n",
       "13  0001008654-20-000048.html   -0.16\n",
       "14  0001104659-20-052683.html   -0.42\n",
       "15  0001104659-20-052792.html   -0.03\n",
       "16  0001104659-20-053353.html    0.65\n",
       "17  0001104659-20-053534.html    0.67\n",
       "18  0001104659-20-053563.html    3.17\n",
       "19  0001140361-20-010070.html    0.38\n",
       "20  0001141391-20-000089.html    1.68\n",
       "21  0001157523-20-000597.html   -0.03\n",
       "22  0001157523-20-000599.html    0.57\n",
       "23  0001157523-20-000600.html    0.11\n",
       "24  0001165002-20-000083.html    0.13\n",
       "25  0001171843-20-003035.html   -6.79\n",
       "26  0001193125-20-124288.html    2.01\n",
       "27  0001193125-20-124568.html    0.30\n",
       "28  0001193125-20-126089.html    1.41\n",
       "29  0001193125-20-126683.html    1.52\n",
       "30  0001289945-20-000036.html   -0.24\n",
       "31  0001299709-20-000078.html    0.91\n",
       "32  0001323885-20-000027.html   -0.42\n",
       "33  0001373715-20-000098.html    0.25\n",
       "34  0001423689-20-000040.html   -3.61\n",
       "35  0001436425-20-000011.html    0.21\n",
       "36  0001538263-20-000014.html      -1\n",
       "37  0001564590-20-019396.html   -3.15\n",
       "38  0001564590-20-019421.html   -0.24\n",
       "39  0001564590-20-019431.html    1.08\n",
       "40  0001564590-20-019442.html    1.00\n",
       "41  0001564590-20-019726.html    0.08\n",
       "42  0001564590-20-019755.html    2.00\n",
       "43  0001564590-20-019760.html   -2.21\n",
       "44  0001576427-20-000032.html    0.62\n",
       "45  0001620459-20-000067.html   -1.21\n",
       "46  0001678463-20-000062.html   -0.22\n",
       "47  0001691303-20-000019.html    0.42\n",
       "48  0001720635-20-000018.html    0.11\n",
       "49  0001722482-20-000089.html    0.05"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =process_directory('Training_Filings_test', verbose=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_df= pd.read_csv('actual_values.csv')\n",
    "actual_df = actual_df[['filename', 'actual_value']]\n",
    "merged_df = pd.merge(df, actual_df, on='filename', how='inner')\n",
    "merged_df['eps'] = merged_df['eps'].astype(float)\n",
    "merged_df['actual_value'] = merged_df['actual_value'].astype(float)\n",
    "exact_matches = (merged_df['eps'] == merged_df['actual_value']).sum()\n",
    "exact_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "actual_value",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "63ac5765-81e1-4e34-b809-77c925aa4303",
       "rows": [
        [
         "2",
         "0000046080-20-000050.html",
         "29.0",
         "-0.51"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>eps</th>\n",
       "      <th>actual_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000046080-20-000050.html</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename   eps  actual_value\n",
       "2  0000046080-20-000050.html  29.0         -0.51"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatches = merged_df[merged_df['eps'] != merged_df['actual_value']]\n",
    "mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BELOW HERE IS TESTING CODE !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eps",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "actual_value",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6008b8f7-6894-4f6b-9f0c-d221a647bd8b",
       "rows": [
        [
         "0",
         "0000004977-20-000054.html",
         "0.78",
         "0.78"
        ],
        [
         "1",
         "0000008947-20-000044.html",
         "-0.41",
         "-0.41"
        ],
        [
         "2",
         "0000046080-20-000050.html",
         null,
         "-0.51"
        ],
        [
         "3",
         "0000066570-20-000013.html",
         "1.12",
         "1.12"
        ],
        [
         "4",
         "0000314808-20-000062.html",
         "-15.19",
         "-15.19"
        ],
        [
         "5",
         "0000706129-20-000012.html",
         "0.26",
         "0.26"
        ],
        [
         "6",
         "0000846617-20-000024.html",
         "0.47",
         "0.47"
        ],
        [
         "7",
         "0000874766-20-000033.html",
         "1.0",
         "0.74"
        ],
        [
         "8",
         "0000875320-20-000014.html",
         "2.32",
         "2.32"
        ],
        [
         "9",
         "0000892537-20-000010.html",
         "0.71",
         "0.71"
        ],
        [
         "10",
         "0000895419-20-000042.html",
         "-0.57",
         "-0.57"
        ],
        [
         "11",
         "0000939057-20-000186.html",
         "0.61",
         "2.01"
        ],
        [
         "12",
         "0000950103-20-008424.html",
         "0.24",
         "0.24"
        ],
        [
         "13",
         "0001008654-20-000048.html",
         "-0.16",
         "-0.16"
        ],
        [
         "14",
         "0001104659-20-052683.html",
         "-0.42",
         "-0.42"
        ],
        [
         "15",
         "0001104659-20-052792.html",
         null,
         null
        ],
        [
         "16",
         "0001104659-20-053353.html",
         "0.65",
         "0.65"
        ],
        [
         "17",
         "0001104659-20-053534.html",
         "0.67",
         "0.67"
        ],
        [
         "18",
         "0001104659-20-053563.html",
         "3.17",
         "3.17"
        ],
        [
         "19",
         "0001140361-20-010070.html",
         "0.38",
         "0.38"
        ],
        [
         "20",
         "0001141391-20-000089.html",
         "1.68",
         "1.68"
        ],
        [
         "21",
         "0001157523-20-000597.html",
         "-0.03",
         "0.3"
        ],
        [
         "22",
         "0001157523-20-000599.html",
         "0.57",
         "0.57"
        ],
        [
         "23",
         "0001157523-20-000600.html",
         "0.11",
         "0.11"
        ],
        [
         "24",
         "0001165002-20-000083.html",
         "0.13",
         "0.13"
        ],
        [
         "25",
         "0001171843-20-003035.html",
         "-6.79",
         "-6.79"
        ],
        [
         "26",
         "0001193125-20-124288.html",
         "2.01",
         "2.01"
        ],
        [
         "27",
         "0001193125-20-124568.html",
         "0.3",
         "0.3"
        ],
        [
         "28",
         "0001193125-20-126089.html",
         "1.41",
         "1.41"
        ],
        [
         "29",
         "0001193125-20-126683.html",
         "1.52",
         "1.52"
        ],
        [
         "30",
         "0001289945-20-000036.html",
         "-0.24",
         "-0.24"
        ],
        [
         "31",
         "0001299709-20-000078.html",
         "0.91",
         "0.91"
        ],
        [
         "32",
         "0001323885-20-000027.html",
         "-0.42",
         "-0.42"
        ],
        [
         "33",
         "0001373715-20-000098.html",
         "0.25",
         "0.25"
        ],
        [
         "34",
         "0001423689-20-000040.html",
         "-3.61",
         "-3.61"
        ],
        [
         "35",
         "0001436425-20-000011.html",
         "0.21",
         "0.21"
        ],
        [
         "36",
         "0001538263-20-000014.html",
         "-1.0",
         null
        ],
        [
         "37",
         "0001564590-20-019396.html",
         "-3.15",
         "-3.15"
        ],
        [
         "38",
         "0001564590-20-019421.html",
         "-0.24",
         "-0.24"
        ],
        [
         "39",
         "0001564590-20-019431.html",
         "1.08",
         "1.08"
        ],
        [
         "40",
         "0001564590-20-019442.html",
         "1.0",
         "1.0"
        ],
        [
         "41",
         "0001564590-20-019726.html",
         "0.08",
         "0.08"
        ],
        [
         "42",
         "0001564590-20-019755.html",
         "2.0",
         "2.0"
        ],
        [
         "43",
         "0001564590-20-019760.html",
         "-2.21",
         "-2.21"
        ],
        [
         "44",
         "0001576427-20-000032.html",
         "0.62",
         "0.62"
        ],
        [
         "45",
         "0001620459-20-000067.html",
         "-1.21",
         "-1.21"
        ],
        [
         "46",
         "0001678463-20-000062.html",
         "-0.22",
         "-0.22"
        ],
        [
         "47",
         "0001691303-20-000019.html",
         "0.42",
         "0.42"
        ],
        [
         "48",
         "0001720635-20-000018.html",
         "0.11",
         "0.11"
        ],
        [
         "49",
         "0001722482-20-000089.html",
         "0.05",
         "0.05"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 50
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>eps</th>\n",
       "      <th>actual_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000004977-20-000054.html</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000008947-20-000044.html</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000046080-20-000050.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000066570-20-000013.html</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000314808-20-000062.html</td>\n",
       "      <td>-15.19</td>\n",
       "      <td>-15.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0000706129-20-000012.html</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0000846617-20-000024.html</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000874766-20-000033.html</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0000875320-20-000014.html</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0000892537-20-000010.html</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0000895419-20-000042.html</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0000939057-20-000186.html</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0000950103-20-008424.html</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0001008654-20-000048.html</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0001104659-20-052683.html</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0001104659-20-052792.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0001104659-20-053353.html</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0001104659-20-053534.html</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0001104659-20-053563.html</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0001140361-20-010070.html</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0001141391-20-000089.html</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0001157523-20-000597.html</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0001157523-20-000599.html</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0001157523-20-000600.html</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0001165002-20-000083.html</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0001171843-20-003035.html</td>\n",
       "      <td>-6.79</td>\n",
       "      <td>-6.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0001193125-20-124288.html</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0001193125-20-124568.html</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0001193125-20-126089.html</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0001193125-20-126683.html</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0001289945-20-000036.html</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0001299709-20-000078.html</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0001323885-20-000027.html</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0001373715-20-000098.html</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0001423689-20-000040.html</td>\n",
       "      <td>-3.61</td>\n",
       "      <td>-3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0001436425-20-000011.html</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0001538263-20-000014.html</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0001564590-20-019396.html</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>-3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0001564590-20-019421.html</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0001564590-20-019431.html</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0001564590-20-019442.html</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0001564590-20-019726.html</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0001564590-20-019755.html</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0001564590-20-019760.html</td>\n",
       "      <td>-2.21</td>\n",
       "      <td>-2.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0001576427-20-000032.html</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0001620459-20-000067.html</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>-1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0001678463-20-000062.html</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0001691303-20-000019.html</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0001720635-20-000018.html</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0001722482-20-000089.html</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filename    eps  actual_value\n",
       "0   0000004977-20-000054.html   0.78          0.78\n",
       "1   0000008947-20-000044.html  -0.41         -0.41\n",
       "2   0000046080-20-000050.html    NaN         -0.51\n",
       "3   0000066570-20-000013.html   1.12          1.12\n",
       "4   0000314808-20-000062.html -15.19        -15.19\n",
       "5   0000706129-20-000012.html   0.26          0.26\n",
       "6   0000846617-20-000024.html   0.47          0.47\n",
       "7   0000874766-20-000033.html   1.00          0.74\n",
       "8   0000875320-20-000014.html   2.32          2.32\n",
       "9   0000892537-20-000010.html   0.71          0.71\n",
       "10  0000895419-20-000042.html  -0.57         -0.57\n",
       "11  0000939057-20-000186.html   0.61          2.01\n",
       "12  0000950103-20-008424.html   0.24          0.24\n",
       "13  0001008654-20-000048.html  -0.16         -0.16\n",
       "14  0001104659-20-052683.html  -0.42         -0.42\n",
       "15  0001104659-20-052792.html    NaN           NaN\n",
       "16  0001104659-20-053353.html   0.65          0.65\n",
       "17  0001104659-20-053534.html   0.67          0.67\n",
       "18  0001104659-20-053563.html   3.17          3.17\n",
       "19  0001140361-20-010070.html   0.38          0.38\n",
       "20  0001141391-20-000089.html   1.68          1.68\n",
       "21  0001157523-20-000597.html  -0.03          0.30\n",
       "22  0001157523-20-000599.html   0.57          0.57\n",
       "23  0001157523-20-000600.html   0.11          0.11\n",
       "24  0001165002-20-000083.html   0.13          0.13\n",
       "25  0001171843-20-003035.html  -6.79         -6.79\n",
       "26  0001193125-20-124288.html   2.01          2.01\n",
       "27  0001193125-20-124568.html   0.30          0.30\n",
       "28  0001193125-20-126089.html   1.41          1.41\n",
       "29  0001193125-20-126683.html   1.52          1.52\n",
       "30  0001289945-20-000036.html  -0.24         -0.24\n",
       "31  0001299709-20-000078.html   0.91          0.91\n",
       "32  0001323885-20-000027.html  -0.42         -0.42\n",
       "33  0001373715-20-000098.html   0.25          0.25\n",
       "34  0001423689-20-000040.html  -3.61         -3.61\n",
       "35  0001436425-20-000011.html   0.21          0.21\n",
       "36  0001538263-20-000014.html  -1.00           NaN\n",
       "37  0001564590-20-019396.html  -3.15         -3.15\n",
       "38  0001564590-20-019421.html  -0.24         -0.24\n",
       "39  0001564590-20-019431.html   1.08          1.08\n",
       "40  0001564590-20-019442.html   1.00          1.00\n",
       "41  0001564590-20-019726.html   0.08          0.08\n",
       "42  0001564590-20-019755.html   2.00          2.00\n",
       "43  0001564590-20-019760.html  -2.21         -2.21\n",
       "44  0001576427-20-000032.html   0.62          0.62\n",
       "45  0001620459-20-000067.html  -1.21         -1.21\n",
       "46  0001678463-20-000062.html  -0.22         -0.22\n",
       "47  0001691303-20-000019.html   0.42          0.42\n",
       "48  0001720635-20-000018.html   0.11          0.11\n",
       "49  0001722482-20-000089.html   0.05          0.05"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "import re \n",
    "def extract_numeric_value(text):\n",
    "    \"\"\"Extract and normalize a numeric value, handling negative numbers in various formats\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "        \n",
    "    # Clean the text\n",
    "    cleaned_text = text.replace('$', '').replace(',', '').strip()\n",
    "    \n",
    "    # Handle case where opening parenthesis is present but closing one is missing\n",
    "    # This happens when parentheses are split across cells\n",
    "    if cleaned_text.startswith('(') and not cleaned_text.endswith(')'):\n",
    "        match = re.search(r'\\(?([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle normal parentheses case\n",
    "    if '(' in cleaned_text and ')' in cleaned_text:\n",
    "        # Extract the number inside parentheses\n",
    "        match = re.search(r'\\(([\\d\\.]+)\\)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle numbers with explicit negative signs\n",
    "    if re.search(r'^\\s*[\\-−–]', cleaned_text):  # Handle various dash characters\n",
    "        match = re.search(r'([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Special case for closing parenthesis only - ignore it\n",
    "    if cleaned_text == ')':\n",
    "        return None\n",
    "    \n",
    "    # Normal number extraction\n",
    "    match = re.search(r'([\\d\\.]+)', cleaned_text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    return None\n",
    "def check_eps_pattern(text):\n",
    "    \"\"\"Expanded pattern checking for EPS-related text\"\"\"\n",
    "    text = text.lower().strip()\n",
    "    patterns = [\n",
    "        r'(?:basic|diluted)?\\s*earnings\\s*(?:\\(loss\\))?\\s*per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'(?:basic|diluted)?\\s*loss\\s*per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'earnings\\s*\\(loss\\)\\s*per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'net\\s*(?:income|loss|earnings)\\s*(?:attributable\\s*to\\s*[a-z\\s]+)?\\s*per\\s*share',\n",
    "        r'income\\s*\\(loss\\)\\s*per\\s*share',\n",
    "        r'\\beps\\b',\n",
    "       # r'per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'earnings\\s*per\\s*share'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            # Exclude weighted average share patterns\n",
    "            if re.search(r'weighted|average|shares\\s*outstanding', text, re.IGNORECASE):\n",
    "                continue\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "def is_basic_eps(text):\n",
    "    \"\"\"Check if text refers to basic EPS (not diluted)\"\"\"\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        has_basic = bool(re.search(r'\\bbasic\\b', text))\n",
    "        has_diluted = bool(re.search(r'\\bdiluted\\b', text))\n",
    "        return has_basic,has_diluted\n",
    "    except Exception as e:\n",
    "        print(f\"Error in is_basic_eps: {e}\")\n",
    "        return False\n",
    "def is_gaap_eps(text):\n",
    "    \"\"\"Check if text refers to GAAP (not non-GAAP/adjusted) EPS\"\"\"\n",
    "    text = text.lower()\n",
    "    return not re.search(r'non-gaap|non\\s*gaap|adjusted', text)\n",
    "def select_eps_value(row_values, row_text, table_idx):\n",
    "    \"\"\"\n",
    "    Helper method to select the appropriate EPS value based on priority rules\n",
    "    and create the final EPS entry dictionary.\n",
    "    \n",
    "    Args:\n",
    "        row_values: List of dictionaries containing EPS values and classifications\n",
    "        row_text: Text from the row where EPS pattern was found\n",
    "        table_idx: Table index for reference\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with selected EPS information\n",
    "    \"\"\"\n",
    "    if not row_values:\n",
    "        return None\n",
    "        \n",
    "    # Default to the first value entry\n",
    "    selected_entry = row_values[0]\n",
    "    \n",
    "    # First try to find basic EPS\n",
    "    basic_values = [item for item in row_values if item['basic']]\n",
    "    if basic_values:\n",
    "        selected_entry = basic_values[0]\n",
    "        print(f\"Selected basic EPS value: {selected_entry['value']}\")\n",
    "    else:\n",
    "        # If no basic found, try diluted\n",
    "        diluted_values = [item for item in row_values if item['diluted']]\n",
    "        if diluted_values:\n",
    "            selected_entry = diluted_values[0]\n",
    "            print(f\"No basic EPS found, using diluted: {selected_entry['value']}\")\n",
    "        else:\n",
    "            print(f\"No specific classification found, using first value: {selected_entry['value']}\")\n",
    "    \n",
    "    # Extract just the values for cleaner output\n",
    "    value_list = [item['value'] for item in row_values]\n",
    "    \n",
    "    # Create the final EPS entry\n",
    "    return {\n",
    "        'table_idx': table_idx,\n",
    "        'row_text': row_text[:100],  # Truncate for readability\n",
    "        'basic': selected_entry['basic'],\n",
    "        'diluted': selected_entry['diluted'],\n",
    "        'gaap': selected_entry['gaap'],\n",
    "        'value': selected_entry['value'],  # Prioritized value\n",
    "        'all_values': value_list\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Filings/0000066570-20-000013.html\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m rows \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rows):\n\u001b[0;32m---> 12\u001b[0m     basic,diluted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     row_text \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_eps_pattern(row_text):\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Look for cells containing a value\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "file_path = 'Training_Filings/0000066570-20-000013.html'\n",
    "print(file_path)\n",
    "with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    html = f.read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "result = []\n",
    "for table in tables:\n",
    "    # Look for rows containing EPS terms\n",
    "    rows = table.find_all('tr')\n",
    "    for i, row in enumerate(rows):\n",
    "        basic,diluted = None\n",
    "        row_text = row.get_text().lower().strip()\n",
    "        if check_eps_pattern(row_text):\n",
    "            # Look for cells containing a value\n",
    "            cells = row.find_all('td')\n",
    "            print(f\"Found EPS pattern in row: {row_text[:100]}...\")\n",
    "            for cell in cells:\n",
    "                value = extract_numeric_value(cell.get_text())\n",
    "                if value is not None: \n",
    "                    ###RETURN BASIC AND DILUTED AND VALUE WE WANT THE FIRST VALUE OF A ROW I THINK \n",
    "                    print(value)\n",
    "                    basic,diluted = is_basic_eps(row_text)\n",
    "                    eps_values.append({\n",
    "                        'basic': basic,\n",
    "                        'diluted': diluted,\n",
    "                        'value': numeric_value\n",
    "                    })\n",
    "                else:\n",
    "                    next_row = rows[i + 1]\n",
    "                    next_cells = next_row.find_all('td')\n",
    "                    print(f\"No values found in current row, checking next row...\")\n",
    "                    for cell in next_cells:\n",
    "                        value = extract_numeric_value(cell.get_text())\n",
    "                        if value is not None:\n",
    "                            print(f\"Found value in next row: {value}\")\n",
    "            \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Filings_test/0000314808-20-000062.html\n",
      "Found EPS pattern in row: loss per share - basic and diluted$(15.19) $(1.09)...\n",
      "Found value in current row: -15.19\n",
      "Found value in current row: -1.09\n",
      "Found EPS pattern in row: loss per share reconciliation(1):three months ended...\n",
      "Found value in current row: -1\n",
      "Found EPS pattern in row: income (loss) from continuing operations attributable to valaris shares earnings (loss) per share fr...\n",
      "No values found in current row, checking next row...\n",
      "Found value in next row: -3006.3\n",
      "Found value in next row: -15.19\n",
      "Found value in next row: -216.0\n",
      "Found value in next row: -1.09\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Training_Filings_test/0000314808-20-000062.html'\n",
    "print(file_path)\n",
    "\n",
    "# Initialize the results list\n",
    "eps_values = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    html = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "for table_idx, table in enumerate(tables):\n",
    "    # Get all rows for sequential access\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = row.get_text().lower().strip()\n",
    "        \n",
    "        if check_eps_pattern(row_text):\n",
    "            # Look for cells containing a value in current row\n",
    "            cells = row.find_all('td')\n",
    "            print(f\"Found EPS pattern in row: {row_text[:100]}...\")\n",
    "            \n",
    "            # Get basic/diluted classification\n",
    "            basic, diluted = is_basic_eps(row_text)\n",
    "            \n",
    "            # Get GAAP classification\n",
    "            gaap = is_gaap_eps(row_text)\n",
    "            \n",
    "            # Check if this row has values\n",
    "            found_value = False\n",
    "            row_values = []\n",
    "            \n",
    "            for cell in cells:\n",
    "                value = extract_numeric_value(cell.get_text())\n",
    "                if value is not None:\n",
    "                    found_value = True\n",
    "                    row_values.append({\n",
    "                        'value': value,\n",
    "                        'basic': basic,\n",
    "                        'diluted': diluted,\n",
    "                        'gaap': gaap\n",
    "                    })\n",
    "                    print(f\"Found value in current row: {value}\")\n",
    "            \n",
    "            # If no values found in current row, check the next row if available\n",
    "            if not found_value and i + 1 < len(rows):\n",
    "                next_row = rows[i + 1]\n",
    "                next_cells = next_row.find_all('td')\n",
    "                next_row_text = next_row.get_text().lower().strip()\n",
    "                basic, diluted = is_basic_eps(next_row_text)\n",
    "                gaap = is_gaap_eps(next_row_text)\n",
    "                print(f\"No values found in current row, checking next row...\")\n",
    "                \n",
    "                for cell in next_cells:\n",
    "                    value = extract_numeric_value(cell.get_text())\n",
    "                    if value is not None:\n",
    "                        row_values.append({\n",
    "                            'value': value,\n",
    "                            'basic': basic,\n",
    "                            'diluted': diluted,\n",
    "                            'gaap': gaap\n",
    "                        })\n",
    "                        print(f\"Found value in next row: {value}\")\n",
    "            \n",
    "            # If we found at least one value (in either current or next row), record it\n",
    "            if row_values:\n",
    "                eps_entry = select_eps_value(row_values, row_text, table_idx)\n",
    "                eps_values.append(eps_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'table_idx': 7,\n",
       "  'row_text': 'loss per share - basic and diluted$(15.19)\\xa0$(1.09)',\n",
       "  'basic': True,\n",
       "  'diluted': True,\n",
       "  'gaap': True,\n",
       "  'value': '-15.19',\n",
       "  'all_values': ['-15.19', '-1.09']},\n",
       " {'table_idx': 19,\n",
       "  'row_text': 'loss per share reconciliation(1):three months ended',\n",
       "  'basic': False,\n",
       "  'diluted': False,\n",
       "  'gaap': True,\n",
       "  'value': '-1',\n",
       "  'all_values': ['-1']},\n",
       " {'table_idx': 19,\n",
       "  'row_text': 'income (loss) from continuing operations attributable to valaris shares\\xa0earnings (loss) per share fr',\n",
       "  'basic': False,\n",
       "  'diluted': False,\n",
       "  'gaap': True,\n",
       "  'value': '-3006.3',\n",
       "  'all_values': ['-3006.3', '-15.19', '-216.0', '-1.09']}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Earnings per share attributable to MSA Safety ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Basic</td>\n",
       "      <td>$</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>0.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Diluted</td>\n",
       "      <td>$</td>\n",
       "      <td>1.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>0.59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0    1     2    3    4  \\\n",
       "26  Earnings per share attributable to MSA Safety ...  NaN   NaN  NaN  NaN   \n",
       "27                                              Basic    $  1.12  NaN  NaN   \n",
       "28                                            Diluted    $  1.11  NaN  NaN   \n",
       "\n",
       "      5     6    7  \n",
       "26  NaN   NaN  NaN  \n",
       "27    $  0.60  NaN  \n",
       "28    $  0.59  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
