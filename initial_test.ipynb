{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "import re\n",
    "\n",
    "def extract_numeric_value(text):\n",
    "    \"\"\"\n",
    "    Extract and normalize a numeric value, handling negative numbers in various formats.\n",
    "    \n",
    "    Args:\n",
    "        text: Text containing a potential numeric value\n",
    "        \n",
    "    Returns:\n",
    "        Normalized numeric value as a string, or None if no valid number found\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "        \n",
    "    # Clean the text\n",
    "    cleaned_text = text.replace('$', '').replace(',', '').strip()\n",
    "    \n",
    "    # Handle case where opening parenthesis is present but closing one is missing\n",
    "    # This happens when parentheses are split across cells\n",
    "    if cleaned_text.startswith('(') and not cleaned_text.endswith(')'):\n",
    "        match = re.search(r'\\(?([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle normal parentheses case\n",
    "    if '(' in cleaned_text and ')' in cleaned_text:\n",
    "        # Extract the number inside parentheses\n",
    "        match = re.search(r'\\(([\\d\\.]+)\\)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle numbers with explicit negative signs\n",
    "    if re.search(r'^\\s*[\\-−–]', cleaned_text):  # Handle various dash characters\n",
    "        match = re.search(r'([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Special case for closing parenthesis only - ignore it\n",
    "    if cleaned_text == ')':\n",
    "        return None\n",
    "    \n",
    "    # Normal number extraction\n",
    "    match = re.search(r'([\\d\\.]+)', cleaned_text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def check_eps_pattern(text):\n",
    "    \"\"\"\n",
    "    Check if text contains patterns indicating EPS (Earnings Per Share) information.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to check for EPS patterns\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating if an EPS pattern was found\n",
    "    \"\"\"\n",
    "    text = text.lower().strip()\n",
    "    patterns = [\n",
    "        r'(?:basic|diluted)?\\s*earnings\\s*(?:\\(loss\\))?\\s*per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'(?:basic|diluted)?\\s*loss\\s*per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'earnings\\s*\\(loss\\)\\s*per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'net\\s*(?:income|loss|earnings)\\s*(?:attributable\\s*to\\s*[a-z\\s]+)?\\s*per\\s*share',\n",
    "        r'income\\s*\\(loss\\)\\s*per\\s*share',\n",
    "        r'\\beps\\b',\n",
    "        r'earnings\\s*per\\s*share',\n",
    "        r'net\\s+income\\s+available\\s+to\\s+common\\s+stockholders\\s+per\\s+share',\n",
    "        r'net\\s+income\\s+per\\s+common\\s+share'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            # Exclude weighted average share patterns\n",
    "            if re.search(r'weighted|average|shares\\s*outstanding', text, re.IGNORECASE):\n",
    "                continue\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def is_basic_eps(text):\n",
    "    \"\"\"\n",
    "    Check if text refers to basic EPS, diluted EPS, or both.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to check for basic/diluted indicators\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (is_basic, is_diluted) booleans\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        has_basic = bool(re.search(r'\\bbasic\\b', text))\n",
    "        has_diluted = bool(re.search(r'\\bdiluted\\b', text))\n",
    "                # Special case: \"basic and diluted\" or \"basic & diluted\" should count as both\n",
    "        if re.search(r'basic\\s+(?:and|&)\\s+diluted', text) or re.search(r'diluted\\s+(?:and|&)\\s+basic', text):\n",
    "            has_basic = True\n",
    "            has_diluted = True\n",
    "            print('HERE IN basic')\n",
    "        return has_basic, has_diluted\n",
    "    except Exception as e:\n",
    "        print(f\"Error in is_basic_eps: {e}\")\n",
    "        return False, False\n",
    "\n",
    "def is_gaap_eps(text):\n",
    "    \"\"\"\n",
    "    Check if text refers to GAAP (not non-GAAP/adjusted) EPS.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to check for GAAP/non-GAAP indicators\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating if EPS is GAAP (True) or non-GAAP (False)\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    return not re.search(r'non-gaap|non\\s*gaap|adjusted', text)\n",
    "\n",
    "def select_eps_value(row_values, row_text, table_idx):\n",
    "    \"\"\"\n",
    "    Select the appropriate EPS value based on priority rules and create the final EPS entry.\n",
    "    \n",
    "    Args:\n",
    "        row_values: List of dictionaries containing EPS values and classifications\n",
    "        row_text: Text from the row where EPS pattern was found\n",
    "        table_idx: Table index for reference\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with selected EPS information\n",
    "    \"\"\"\n",
    "    if not row_values:\n",
    "        return None\n",
    "        \n",
    "    # Default to the first value entry\n",
    "    selected_entry = row_values[0]\n",
    "    \n",
    "    # First try to find basic EPS (highest priority)\n",
    "    basic_values = [item for item in row_values if item['basic']]\n",
    "    if basic_values:\n",
    "        selected_entry = basic_values[0]\n",
    "    else:\n",
    "        # If no basic found, try diluted\n",
    "        diluted_values = [item for item in row_values if item['diluted']]\n",
    "        if diluted_values:\n",
    "            selected_entry = diluted_values[0]\n",
    "    \n",
    "    # Extract just the values for cleaner output\n",
    "    value_list = [item['value'] for item in row_values]\n",
    "    \n",
    "    # Create the final EPS entry\n",
    "    return {\n",
    "        'table_idx': table_idx,\n",
    "        'row_text': row_text[:100],  # Truncate for readability\n",
    "        'basic': selected_entry['basic'],\n",
    "        'diluted': selected_entry['diluted'],\n",
    "        'gaap': selected_entry['gaap'],\n",
    "        'value': selected_entry['value'],  # Prioritized value\n",
    "        'all_values': value_list\n",
    "    }\n",
    "\n",
    "def extract_eps_from_filing(file_path, verbose=False):\n",
    "    \"\"\"\n",
    "    Extract EPS values from an HTML financial filing.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the HTML filing\n",
    "        verbose: Whether to print detailed information during extraction\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing extracted EPS information\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # Initialize the results list\n",
    "    eps_values = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        html = f.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    for table_idx, table in enumerate(tables):\n",
    "        # Get all rows for sequential access\n",
    "        rows = table.find_all('tr')\n",
    "        \n",
    "        for i, row in enumerate(rows):\n",
    "            row_text = row.get_text().lower().strip().replace(':', '')\n",
    "            \n",
    "            if check_eps_pattern(row_text):\n",
    "                # Look for cells containing a value in current row\n",
    "                cells = row.find_all('td')\n",
    "                if verbose:\n",
    "                    print(f\"Found EPS pattern in row: {row_text[:100]}...\")\n",
    "                \n",
    "                # Get basic/diluted classification\n",
    "                basic, diluted = is_basic_eps(row_text)\n",
    "                \n",
    "                # Get GAAP classification\n",
    "                gaap = is_gaap_eps(row_text)\n",
    "                \n",
    "                # Check if this row has values\n",
    "                found_value = False\n",
    "                row_values = []\n",
    "                \n",
    "                for cell in cells:\n",
    "                    cell_text = cell.get_text().strip()\n",
    "                    \n",
    "                    value = extract_numeric_value(cell_text)\n",
    "    \n",
    "                    if value is not None:\n",
    "                        found_value = True\n",
    "                        \n",
    "                        row_values.append({\n",
    "                            'value': value,\n",
    "                            'basic': basic,\n",
    "                            'diluted': diluted,\n",
    "                            'gaap': gaap\n",
    "                        })\n",
    "                        \n",
    "                        if verbose:\n",
    "                            print(f\"Found value in current row: {value}\")\n",
    "                \n",
    "                # If no values found in current row or we suspect partial parentheses, check the next row\n",
    "                if (not found_value and i + 1 < len(rows)):\n",
    "                    next_row = rows[i + 1]\n",
    "                    next_cells = next_row.find_all('td')\n",
    "                    next_row_text = next_row.get_text().lower().strip().replace(':', '')\n",
    "                    \n",
    "                    # Get classifications from next row\n",
    "                    if not(basic and diluted):\n",
    "                        basic, diluted = is_basic_eps(next_row_text)\n",
    "                    gaap = is_gaap_eps(next_row_text)\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"Checking next row for values...\")\n",
    "                        print(next_row_text)\n",
    "                    for cell in next_cells:\n",
    "                        cell_text = cell.get_text().strip()\n",
    "                        value = extract_numeric_value(cell_text)\n",
    "                        \n",
    "                        if value is not None:\n",
    "                            row_values.append({\n",
    "                                'value': value,\n",
    "                                'basic': basic,\n",
    "                                'diluted': diluted,\n",
    "                                'gaap': gaap\n",
    "                            })\n",
    "                            \n",
    "                            if verbose:\n",
    "                                print(f\"Found value in next row: {value}\")\n",
    "                \n",
    "                # If we found at least one value, use helper method to select and create entry\n",
    "                if row_values:\n",
    "                    eps_entry = select_eps_value(row_values, row_text, table_idx)\n",
    "                    eps_values.append(eps_entry)\n",
    "    \n",
    "    return eps_values\n",
    "\n",
    "def process_directory(directory_path, verbose=False):\n",
    "    \"\"\"\n",
    "    Process all HTML files in a directory to extract EPS values.\n",
    "    \n",
    "    Args:\n",
    "        directory_path: Path to directory containing HTML filings\n",
    "        verbose: Whether to print detailed information during extraction\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing all extracted EPS information\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.html'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            results = extract_eps_from_filing(file_path, verbose=verbose)\n",
    "            \n",
    "            for result in results:\n",
    "                result['filename'] = filename\n",
    "            \n",
    "            all_results.extend(results)\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    df = pd.DataFrame(all_results)\n",
    "    return df\n",
    "def select_final_eps(eps_values):\n",
    "    \"\"\"\n",
    "    Select the final EPS value from all extracted values based on row text patterns and priority rules.\n",
    "    \n",
    "    Args:\n",
    "        eps_values: List of dictionaries containing extracted EPS information\n",
    "        \n",
    "    Returns:\n",
    "        Single EPS value or None if no valid value found\n",
    "    \"\"\"\n",
    "    if not eps_values:\n",
    "        return None\n",
    "    \n",
    "    # If there's only one value, return it directly\n",
    "    if len(eps_values) == 1:\n",
    "        return eps_values[0]['value']\n",
    "    \n",
    "    # Define pattern priority list (highest priority first)\n",
    "    # Each entry is (regex pattern, score adjustment)\n",
    "    pattern_priorities = [\n",
    "        # Basic net income/earnings per share (highest priority)\n",
    "        (r'basic\\s+(?:and|&)\\s+diluted\\s+(?:loss|earnings|income)\\s+per\\s+share', 1200),\n",
    "        (r'(?:loss|earnings|income)\\s+per\\s+share\\s+[-–]\\s+basic\\s+(?:and|&)\\s+diluted', 1200),\n",
    "        (r'basic.*net\\s+(?:income|earnings).*per\\s+share', 1000),\n",
    "        \n",
    "        # Basic EPS patterns (very high priority)\n",
    "        (r'basic\\s+earnings\\s+per\\s+(?:common\\s+)?share', 900),\n",
    "        (r'earnings\\s+per\\s+(?:common\\s+)?share.*basic', 900),\n",
    "        (r'net\\s+income.*per\\s+(?:common\\s+)?share.*basic', 900),\n",
    "        \n",
    "        # Important: Add patterns for \"earnings (loss)\" format (high priority)\n",
    "        (r'earnings\\s*\\(loss\\)\\s*per\\s+(?:common\\s+)?share', 850),\n",
    "        (r'net\\s+earnings\\s*\\(loss\\)\\s*per\\s+share', 850),\n",
    "        (r'\\(loss\\)\\s*earnings\\s*per\\s+(?:common\\s+)?share', 850),\n",
    "        \n",
    "        # Income/earnings per share (likely basic if not specified)\n",
    "        (r'net\\s+(?:income|earnings).*per\\s+share', 800),\n",
    "        (r'net\\s+income\\s+per\\s+common\\s+share', 800),  # High priority\n",
    "        (r'income.*per\\s+share', 700),\n",
    "        (r'earnings\\s+per\\s+(?:common\\s+)?share', 700),\n",
    "        \n",
    "        # Loss per share (still high priority)\n",
    "        (r'basic.*loss\\s+per\\s+share', 650),\n",
    "        (r'net\\s+loss.*per\\s+share', 650),\n",
    "        (r'loss\\s+per\\s+share', 650),\n",
    "        \n",
    "        # GAAP EPS terms\n",
    "        (r'gaap.*earnings\\s+per\\s+share', 600),\n",
    "        \n",
    "        # Specific types of basic EPS\n",
    "        (r'basic\\s+.*per\\s+share', 550),\n",
    "        \n",
    "        # Diluted net income/earnings per share (medium priority)\n",
    "        (r'diluted.*net\\s+(?:income|earnings).*per\\s+share', 500),\n",
    "        \n",
    "        # Diluted EPS patterns\n",
    "        (r'diluted\\s+earnings\\s+per\\s+(?:common\\s+)?share', 400),\n",
    "        (r'earnings\\s+per\\s+(?:common\\s+)?share.*diluted', 400),\n",
    "        \n",
    "        # Generic diluted patterns\n",
    "        (r'diluted\\s+.*per\\s+share', 300),\n",
    "        \n",
    "        # Non-GAAP or adjusted terms (lower priority)\n",
    "        (r'adjusted\\s+(?:basic\\s+)?earnings\\s+per\\s+share', 200),\n",
    "        (r'non-gaap.*earnings\\s+per\\s+share', 100),\n",
    "        (r'adjusted', 50),\n",
    "        \n",
    "        # Generic EPS terms (lowest priority, but still valid)\n",
    "        (r'per\\s+share', 25),\n",
    "        (r'eps', 20),\n",
    "    ]\n",
    "    \n",
    "    scored_values = []\n",
    "    for idx, entry in enumerate(eps_values):\n",
    "        # Start with a base score\n",
    "        score = 0\n",
    "        row_text = entry['row_text'].lower().replace(':', '')\n",
    "        \n",
    "        # Debug - print the exact row text being matched\n",
    "        print(f\"Matching text: '{row_text}'\")\n",
    "        \n",
    "        # Add score based on pattern matches\n",
    "        matched_pattern = None\n",
    "        for pattern, pattern_score in pattern_priorities:\n",
    "            if re.search(pattern, row_text):\n",
    "                score += pattern_score\n",
    "                matched_pattern = pattern\n",
    "                break  # Only apply the highest matching pattern\n",
    "        \n",
    "        # Add additional score components\n",
    "        # 1. Prioritize basic over diluted\n",
    "        if entry['basic']:\n",
    "            score += 100\n",
    "        elif entry['diluted']:\n",
    "            score += 10\n",
    "            \n",
    "        # 2. Prioritize GAAP over non-GAAP\n",
    "        if entry['gaap']:\n",
    "            score += 20\n",
    "        \n",
    "        # 3. Check numerical reasonableness (EPS values are typically between -100 and 100)\n",
    "        try:\n",
    "            value_float = float(entry['value'])\n",
    "            if -20 <= value_float <= 20:\n",
    "                # Most reasonable EPS range\n",
    "                score += 100  # Increased from 15 to 100\n",
    "            elif -100 <= value_float <= 100:\n",
    "                # Wider but still reasonable EPS range\n",
    "                score += 50\n",
    "            elif -1000 <= value_float <= 1000:\n",
    "                # Unusual but possible range\n",
    "                score -= 100  # Increased penalty\n",
    "            else:\n",
    "                # Very likely not an EPS value (e.g., shares outstanding, total earnings in millions)\n",
    "                score -= 500  # Much stronger penalty\n",
    "        except ValueError:\n",
    "            score -= 50  \n",
    "            \n",
    "        scored_values.append({\n",
    "            'index': idx,\n",
    "            'score': score,\n",
    "            'value': entry['value'],\n",
    "            'original': entry,\n",
    "            'row_text': row_text,\n",
    "            'matched_pattern': matched_pattern\n",
    "        })\n",
    "    \n",
    "    # Sort by score in descending order\n",
    "    scored_values.sort(key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    # For debugging\n",
    "    for i, sv in enumerate(scored_values[:3]):  # Show top 3\n",
    "        print(f\"Candidate {i+1}: Score {sv['score']}, Value: {sv['value']}\")\n",
    "        print(f\"  Row text: {sv['row_text'][:80]}...\")\n",
    "        print(f\"  Matched pattern: {sv['matched_pattern']}\")\n",
    "    \n",
    "    # Return the highest scoring value\n",
    "    if scored_values:\n",
    "        top_score = scored_values[0]['score']\n",
    "        top_row_text = scored_values[0]['row_text']\n",
    "        \n",
    "        # Find all entries with the same row text and score\n",
    "        identical_rows = [\n",
    "            sv for sv in scored_values \n",
    "            if sv['score'] == top_score and sv['row_text'] == top_row_text\n",
    "        ]\n",
    "        \n",
    "        if len(identical_rows) > 1:\n",
    "            print(f\"Found {len(identical_rows)} rows with identical text and score: '{top_row_text[:50]}...'\")\n",
    "            \n",
    "            # Sum the values\n",
    "            total_value = 0\n",
    "            for row in identical_rows:\n",
    "                try:\n",
    "                    total_value += float(row['value'])\n",
    "                except ValueError:\n",
    "                    # Skip non-numeric values\n",
    "                    print(f\"Warning: Could not convert '{row['value']}' to float for summation\")\n",
    "            \n",
    "            # Return the sum as a string with the same precision as the original values\n",
    "            # (Get decimal places from the first value as a reference)\n",
    "            try:\n",
    "                decimal_places = len(identical_rows[0]['value'].split('.')[-1]) if '.' in identical_rows[0]['value'] else 0\n",
    "                return f\"{total_value:.{decimal_places}f}\"\n",
    "            except:\n",
    "                # Fallback to basic formatting if precision detection fails\n",
    "                return str(total_value)\n",
    "        \n",
    "        # If no identical rows, return the highest scoring value\n",
    "        return scored_values[0]['value']\n",
    "\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Training_Filings_test/0000950103-20-008424.html\n",
      "Found EPS pattern in row: net income per share attributable to uct common stockholders...\n",
      "Checking next row for values...\n",
      "basic \n",
      "$0.24  \n",
      "$0.02\n",
      "Found value in next row: 0.24\n",
      "Found value in next row: 0.02\n",
      "Found EPS pattern in row: shares used in computing net income per share...\n",
      "Checking next row for values...\n",
      "basic \n",
      " 39,817  \n",
      " 39,122\n",
      "Found value in next row: 39817\n",
      "Found value in next row: 39122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'table_idx': 3,\n",
       "  'row_text': 'net income per share attributable to uct common stockholders',\n",
       "  'basic': True,\n",
       "  'diluted': False,\n",
       "  'gaap': True,\n",
       "  'value': '0.24',\n",
       "  'all_values': ['0.24', '0.02']},\n",
       " {'table_idx': 3,\n",
       "  'row_text': 'shares used in computing net income per share',\n",
       "  'basic': True,\n",
       "  'diluted': False,\n",
       "  'gaap': True,\n",
       "  'value': '39817',\n",
       "  'all_values': ['39817', '39122']}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process a single file\n",
    "file_path = 'Training_Filings_test/0000950103-20-008424.html'\n",
    "results = extract_eps_from_filing(file_path, verbose=True)\n",
    "\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching text: 'net income per share attributable to uct common stockholders'\n",
      "Matching text: 'shares used in computing net income per share'\n",
      "Candidate 1: Score 1020, Value: 0.24\n",
      "  Row text: net income per share attributable to uct common stockholders...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n",
      "Candidate 2: Score 420, Value: 39817\n",
      "  Row text: shares used in computing net income per share...\n",
      "  Matched pattern: net\\s+(?:income|earnings).*per\\s+share\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.24'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_final_eps(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BELOW HERE IS TESTING CODE !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import os \n",
    "import re \n",
    "def extract_numeric_value(text):\n",
    "    \"\"\"Extract and normalize a numeric value, handling negative numbers in various formats\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "        \n",
    "    # Clean the text\n",
    "    cleaned_text = text.replace('$', '').replace(',', '').strip()\n",
    "    \n",
    "    # Handle case where opening parenthesis is present but closing one is missing\n",
    "    # This happens when parentheses are split across cells\n",
    "    if cleaned_text.startswith('(') and not cleaned_text.endswith(')'):\n",
    "        match = re.search(r'\\(?([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle normal parentheses case\n",
    "    if '(' in cleaned_text and ')' in cleaned_text:\n",
    "        # Extract the number inside parentheses\n",
    "        match = re.search(r'\\(([\\d\\.]+)\\)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Handle numbers with explicit negative signs\n",
    "    if re.search(r'^\\s*[\\-−–]', cleaned_text):  # Handle various dash characters\n",
    "        match = re.search(r'([\\d\\.]+)', cleaned_text)\n",
    "        if match:\n",
    "            return f\"-{match.group(1)}\"\n",
    "    \n",
    "    # Special case for closing parenthesis only - ignore it\n",
    "    if cleaned_text == ')':\n",
    "        return None\n",
    "    \n",
    "    # Normal number extraction\n",
    "    match = re.search(r'([\\d\\.]+)', cleaned_text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    return None\n",
    "def check_eps_pattern(text):\n",
    "    \"\"\"Expanded pattern checking for EPS-related text\"\"\"\n",
    "    text = text.lower().strip()\n",
    "    patterns = [\n",
    "        r'(?:basic|diluted)?\\s*earnings\\s*(?:\\(loss\\))?\\s*per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'(?:basic|diluted)?\\s*loss\\s*per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'earnings\\s*\\(loss\\)\\s*per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'net\\s*(?:income|loss|earnings)\\s*(?:attributable\\s*to\\s*[a-z\\s]+)?\\s*per\\s*share',\n",
    "        r'income\\s*\\(loss\\)\\s*per\\s*share',\n",
    "        r'\\beps\\b',\n",
    "       # r'per\\s*(?:common|outstanding)?\\s*share',\n",
    "        r'earnings\\s*per\\s*share'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, text, re.IGNORECASE):\n",
    "            # Exclude weighted average share patterns\n",
    "            if re.search(r'weighted|average|shares\\s*outstanding', text, re.IGNORECASE):\n",
    "                continue\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "def is_basic_eps(text):\n",
    "    \"\"\"Check if text refers to basic EPS (not diluted)\"\"\"\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        has_basic = bool(re.search(r'\\bbasic\\b', text))\n",
    "        has_diluted = bool(re.search(r'\\bdiluted\\b', text))\n",
    "        return has_basic,has_diluted\n",
    "    except Exception as e:\n",
    "        print(f\"Error in is_basic_eps: {e}\")\n",
    "        return False\n",
    "def is_gaap_eps(text):\n",
    "    \"\"\"Check if text refers to GAAP (not non-GAAP/adjusted) EPS\"\"\"\n",
    "    text = text.lower()\n",
    "    return not re.search(r'non-gaap|non\\s*gaap|adjusted', text)\n",
    "def select_eps_value(row_values, row_text, table_idx):\n",
    "    \"\"\"\n",
    "    Helper method to select the appropriate EPS value based on priority rules\n",
    "    and create the final EPS entry dictionary.\n",
    "    \n",
    "    Args:\n",
    "        row_values: List of dictionaries containing EPS values and classifications\n",
    "        row_text: Text from the row where EPS pattern was found\n",
    "        table_idx: Table index for reference\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with selected EPS information\n",
    "    \"\"\"\n",
    "    if not row_values:\n",
    "        return None\n",
    "        \n",
    "    # Default to the first value entry\n",
    "    selected_entry = row_values[0]\n",
    "    \n",
    "    # First try to find basic EPS\n",
    "    basic_values = [item for item in row_values if item['basic']]\n",
    "    if basic_values:\n",
    "        selected_entry = basic_values[0]\n",
    "        print(f\"Selected basic EPS value: {selected_entry['value']}\")\n",
    "    else:\n",
    "        # If no basic found, try diluted\n",
    "        diluted_values = [item for item in row_values if item['diluted']]\n",
    "        if diluted_values:\n",
    "            selected_entry = diluted_values[0]\n",
    "            print(f\"No basic EPS found, using diluted: {selected_entry['value']}\")\n",
    "        else:\n",
    "            print(f\"No specific classification found, using first value: {selected_entry['value']}\")\n",
    "    \n",
    "    # Extract just the values for cleaner output\n",
    "    value_list = [item['value'] for item in row_values]\n",
    "    \n",
    "    # Create the final EPS entry\n",
    "    return {\n",
    "        'table_idx': table_idx,\n",
    "        'row_text': row_text[:100],  # Truncate for readability\n",
    "        'basic': selected_entry['basic'],\n",
    "        'diluted': selected_entry['diluted'],\n",
    "        'gaap': selected_entry['gaap'],\n",
    "        'value': selected_entry['value'],  # Prioritized value\n",
    "        'all_values': value_list\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Filings/0000066570-20-000013.html\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m rows \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(rows):\n\u001b[0;32m---> 12\u001b[0m     basic,diluted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     row_text \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mget_text()\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_eps_pattern(row_text):\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Look for cells containing a value\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "file_path = 'Training_Filings/0000066570-20-000013.html'\n",
    "print(file_path)\n",
    "with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    html = f.read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "result = []\n",
    "for table in tables:\n",
    "    # Look for rows containing EPS terms\n",
    "    rows = table.find_all('tr')\n",
    "    for i, row in enumerate(rows):\n",
    "        basic,diluted = None\n",
    "        row_text = row.get_text().lower().strip()\n",
    "        if check_eps_pattern(row_text):\n",
    "            # Look for cells containing a value\n",
    "            cells = row.find_all('td')\n",
    "            print(f\"Found EPS pattern in row: {row_text[:100]}...\")\n",
    "            for cell in cells:\n",
    "                value = extract_numeric_value(cell.get_text())\n",
    "                if value is not None: \n",
    "                    ###RETURN BASIC AND DILUTED AND VALUE WE WANT THE FIRST VALUE OF A ROW I THINK \n",
    "                    print(value)\n",
    "                    basic,diluted = is_basic_eps(row_text)\n",
    "                    eps_values.append({\n",
    "                        'basic': basic,\n",
    "                        'diluted': diluted,\n",
    "                        'value': numeric_value\n",
    "                    })\n",
    "                else:\n",
    "                    next_row = rows[i + 1]\n",
    "                    next_cells = next_row.find_all('td')\n",
    "                    print(f\"No values found in current row, checking next row...\")\n",
    "                    for cell in next_cells:\n",
    "                        value = extract_numeric_value(cell.get_text())\n",
    "                        if value is not None:\n",
    "                            print(f\"Found value in next row: {value}\")\n",
    "            \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Filings_test/0000314808-20-000062.html\n",
      "Found EPS pattern in row: loss per share - basic and diluted$(15.19) $(1.09)...\n",
      "Found value in current row: -15.19\n",
      "Found value in current row: -1.09\n",
      "Found EPS pattern in row: loss per share reconciliation(1):three months ended...\n",
      "Found value in current row: -1\n",
      "Found EPS pattern in row: income (loss) from continuing operations attributable to valaris shares earnings (loss) per share fr...\n",
      "No values found in current row, checking next row...\n",
      "Found value in next row: -3006.3\n",
      "Found value in next row: -15.19\n",
      "Found value in next row: -216.0\n",
      "Found value in next row: -1.09\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Training_Filings_test/0000314808-20-000062.html'\n",
    "print(file_path)\n",
    "\n",
    "# Initialize the results list\n",
    "eps_values = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    html = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "for table_idx, table in enumerate(tables):\n",
    "    # Get all rows for sequential access\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    for i, row in enumerate(rows):\n",
    "        row_text = row.get_text().lower().strip()\n",
    "        \n",
    "        if check_eps_pattern(row_text):\n",
    "            # Look for cells containing a value in current row\n",
    "            cells = row.find_all('td')\n",
    "            print(f\"Found EPS pattern in row: {row_text[:100]}...\")\n",
    "            \n",
    "            # Get basic/diluted classification\n",
    "            basic, diluted = is_basic_eps(row_text)\n",
    "            \n",
    "            # Get GAAP classification\n",
    "            gaap = is_gaap_eps(row_text)\n",
    "            \n",
    "            # Check if this row has values\n",
    "            found_value = False\n",
    "            row_values = []\n",
    "            \n",
    "            for cell in cells:\n",
    "                value = extract_numeric_value(cell.get_text())\n",
    "                if value is not None:\n",
    "                    found_value = True\n",
    "                    row_values.append({\n",
    "                        'value': value,\n",
    "                        'basic': basic,\n",
    "                        'diluted': diluted,\n",
    "                        'gaap': gaap\n",
    "                    })\n",
    "                    print(f\"Found value in current row: {value}\")\n",
    "            \n",
    "            # If no values found in current row, check the next row if available\n",
    "            if not found_value and i + 1 < len(rows):\n",
    "                next_row = rows[i + 1]\n",
    "                next_cells = next_row.find_all('td')\n",
    "                next_row_text = next_row.get_text().lower().strip()\n",
    "                basic, diluted = is_basic_eps(next_row_text)\n",
    "                gaap = is_gaap_eps(next_row_text)\n",
    "                print(f\"No values found in current row, checking next row...\")\n",
    "                \n",
    "                for cell in next_cells:\n",
    "                    value = extract_numeric_value(cell.get_text())\n",
    "                    if value is not None:\n",
    "                        row_values.append({\n",
    "                            'value': value,\n",
    "                            'basic': basic,\n",
    "                            'diluted': diluted,\n",
    "                            'gaap': gaap\n",
    "                        })\n",
    "                        print(f\"Found value in next row: {value}\")\n",
    "            \n",
    "            # If we found at least one value (in either current or next row), record it\n",
    "            if row_values:\n",
    "                eps_entry = select_eps_value(row_values, row_text, table_idx)\n",
    "                eps_values.append(eps_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'table_idx': 7,\n",
       "  'row_text': 'loss per share - basic and diluted$(15.19)\\xa0$(1.09)',\n",
       "  'basic': True,\n",
       "  'diluted': True,\n",
       "  'gaap': True,\n",
       "  'value': '-15.19',\n",
       "  'all_values': ['-15.19', '-1.09']},\n",
       " {'table_idx': 19,\n",
       "  'row_text': 'loss per share reconciliation(1):three months ended',\n",
       "  'basic': False,\n",
       "  'diluted': False,\n",
       "  'gaap': True,\n",
       "  'value': '-1',\n",
       "  'all_values': ['-1']},\n",
       " {'table_idx': 19,\n",
       "  'row_text': 'income (loss) from continuing operations attributable to valaris shares\\xa0earnings (loss) per share fr',\n",
       "  'basic': False,\n",
       "  'diluted': False,\n",
       "  'gaap': True,\n",
       "  'value': '-3006.3',\n",
       "  'all_values': ['-3006.3', '-15.19', '-216.0', '-1.09']}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Earnings per share attributable to MSA Safety ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Basic</td>\n",
       "      <td>$</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>0.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Diluted</td>\n",
       "      <td>$</td>\n",
       "      <td>1.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>0.59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0    1     2    3    4  \\\n",
       "26  Earnings per share attributable to MSA Safety ...  NaN   NaN  NaN  NaN   \n",
       "27                                              Basic    $  1.12  NaN  NaN   \n",
       "28                                            Diluted    $  1.11  NaN  NaN   \n",
       "\n",
       "      5     6    7  \n",
       "26  NaN   NaN  NaN  \n",
       "27    $  0.60  NaN  \n",
       "28    $  0.59  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
